{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "라이브러리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.utils import *\n",
    "from keras.layers import LSTM, Dense\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from sklearn.preprocessing import *\n",
    "from keras.losses import Huber\n",
    "\n",
    "model_name = 'model/Aqua_all_lstm_nomal'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "japonica_training = pd.DataFrame()\n",
    "japonica_validation = pd.DataFrame()\n",
    "for i in range(5):\n",
    "    tank = i + 1\n",
    "    japonica_training_food_supply_tb = pd.read_csv(\"dataset/japonica_training_food_supply_tb.csv\")\n",
    "    japonica_training_sensor_val_tb = pd.read_csv(\"dataset/japonica_training_sensor_val_tb.csv\")\n",
    "    japonica_validation_food_supply_tb = pd.read_csv(\"dataset/japonica_validation_food_supply_tb.csv\")\n",
    "    japonica_validation_sensor_val_tb = pd.read_csv(\"dataset/japonica_validation_sensor_val_tb.csv\")\n",
    "    japonica_training_food_supply_tb = japonica_training_food_supply_tb[japonica_training_food_supply_tb['tank_id']==tank]\n",
    "    japonica_validation_food_supply_tb = japonica_validation_food_supply_tb[japonica_validation_food_supply_tb['tank_id']==tank]\n",
    "    japonica_training_food_supply_tb = japonica_training_food_supply_tb[japonica_training_food_supply_tb['feed_quantity'].notnull()]\n",
    "    japonica_validation_food_supply_tb = japonica_validation_food_supply_tb[japonica_validation_food_supply_tb['feed_quantity'].notnull()]\n",
    "    japonica_training_food_supply_tb['feed_dt'] = pd.to_datetime(japonica_training_food_supply_tb['feed_dt'], format='%Y%m%d%H%M', errors='raise')\n",
    "    japonica_training_food_supply_tb[\"feed_dt\"] = japonica_training_food_supply_tb[\"feed_dt\"].apply(str)\n",
    "    japonica_training_food_supply_tb[\"feed_dt\"] = japonica_training_food_supply_tb[\"feed_dt\"].str.slice(start=0, stop=16)\n",
    "    japonica_validation_food_supply_tb['feed_dt'] = pd.to_datetime(japonica_validation_food_supply_tb['feed_dt'], format='%Y%m%d%H%M', errors='raise')\n",
    "    japonica_validation_food_supply_tb[\"feed_dt\"] = japonica_validation_food_supply_tb[\"feed_dt\"].apply(str)\n",
    "    japonica_validation_food_supply_tb[\"feed_dt\"] = japonica_validation_food_supply_tb[\"feed_dt\"].str.slice(start=0, stop=16)\n",
    "    japonica_training_sensor_val_tb = japonica_training_sensor_val_tb[japonica_training_sensor_val_tb['tank_id']==tank]\n",
    "    japonica_validation_sensor_val_tb = japonica_validation_sensor_val_tb[japonica_validation_sensor_val_tb['tank_id']==tank]\n",
    "    japonica_training_sensor_val_tb[\"mea_dt\"] = japonica_training_sensor_val_tb[\"mea_dt\"].apply(str)\n",
    "    japonica_training_sensor_val_tb[\"mea_dt\"] = japonica_training_sensor_val_tb[\"mea_dt\"].str.slice(start=0, stop=16)\n",
    "    japonica_training_sensor_val_tb['mea_dt'] = pd.to_datetime(japonica_training_sensor_val_tb['mea_dt'], format='%Y-%m-%d %H:%M', errors='raise')\n",
    "    japonica_validation_sensor_val_tb[\"mea_dt\"] = japonica_validation_sensor_val_tb[\"mea_dt\"].apply(str)\n",
    "    japonica_validation_sensor_val_tb[\"mea_dt\"] = japonica_validation_sensor_val_tb[\"mea_dt\"].str.slice(start=0, stop=16)\n",
    "    japonica_validation_sensor_val_tb['mea_dt'] = pd.to_datetime(japonica_validation_sensor_val_tb['mea_dt'], format='%Y-%m-%d %H:%M', errors='raise')\n",
    "    japonica_training_sensor_val_tb['date'] = pd.to_datetime(japonica_training_sensor_val_tb['mea_dt']).dt.date\n",
    "    japonica_training_food_supply_tb['date'] = pd.to_datetime(japonica_training_food_supply_tb['feed_dt']).dt.date\n",
    "    common_dates = japonica_training_sensor_val_tb['date'].isin(japonica_training_food_supply_tb['date'])\n",
    "    japonica_training_sensor_val_tb = japonica_training_sensor_val_tb[common_dates]\n",
    "    japonica_training_sensor_val_tb = japonica_training_sensor_val_tb.drop('date', axis=1)\n",
    "    japonica_validation_sensor_val_tb['date'] = pd.to_datetime(japonica_validation_sensor_val_tb['mea_dt']).dt.date\n",
    "    japonica_validation_food_supply_tb['date'] = pd.to_datetime(japonica_validation_food_supply_tb['feed_dt']).dt.date\n",
    "    common_dates = japonica_validation_sensor_val_tb['date'].isin(japonica_validation_food_supply_tb['date'])\n",
    "    japonica_validation_sensor_val_tb = japonica_validation_sensor_val_tb[common_dates]\n",
    "    japonica_validation_sensor_val_tb = japonica_validation_sensor_val_tb.drop('date', axis=1)\n",
    "    japonica_training_sensor_val_tb.set_index('mea_dt', inplace=True)\n",
    "    japonica_training_sensor_val_tb = japonica_training_sensor_val_tb.resample('30min').mean()\n",
    "    japonica_training_sensor_val_tb = japonica_training_sensor_val_tb.reset_index()\n",
    "    japonica_training_sensor_val_tb = japonica_training_sensor_val_tb.dropna()\n",
    "    japonica_validation_sensor_val_tb.set_index('mea_dt', inplace=True)\n",
    "    japonica_validation_sensor_val_tb = japonica_validation_sensor_val_tb.resample('30min').mean()\n",
    "    japonica_validation_sensor_val_tb = japonica_validation_sensor_val_tb.reset_index()\n",
    "    japonica_validation_sensor_val_tb = japonica_validation_sensor_val_tb.dropna()\n",
    "    training_counts = japonica_training_sensor_val_tb.groupby(japonica_training_sensor_val_tb['mea_dt'].dt.date).size()\n",
    "    validation_counts = japonica_validation_sensor_val_tb.groupby(japonica_validation_sensor_val_tb['mea_dt'].dt.date).size()\n",
    "    to_delete = training_counts[training_counts != 48].index\n",
    "    japonica_training_sensor_val_tb = japonica_training_sensor_val_tb[~japonica_training_sensor_val_tb['mea_dt'].dt.date.isin(to_delete)]\n",
    "    to_delete = validation_counts[validation_counts != 48].index\n",
    "    japonica_validation_sensor_val_tb = japonica_validation_sensor_val_tb[~japonica_validation_sensor_val_tb['mea_dt'].dt.date.isin(to_delete)]\n",
    "    japonica_training_sensor_val_tb[\"mea_dt\"] = japonica_training_sensor_val_tb[\"mea_dt\"].dt.strftime('%Y-%m-%d %H:%M')\n",
    "    japonica_training_sensor_val_tb[\"mea_dt\"] = japonica_training_sensor_val_tb[\"mea_dt\"].str.slice(start=0, stop=16)\n",
    "    japonica_validation_sensor_val_tb[\"mea_dt\"] = japonica_validation_sensor_val_tb[\"mea_dt\"].dt.strftime('%Y-%m-%d %H:%M')\n",
    "    japonica_validation_sensor_val_tb[\"mea_dt\"] = japonica_validation_sensor_val_tb[\"mea_dt\"].str.slice(start=0, stop=16)\n",
    "    japonica_training_features = pd.merge(left = japonica_training_sensor_val_tb, right = japonica_training_food_supply_tb, how = \"left\", left_on = [\"farm_id\",\"tank_id\", \"mea_dt\"], right_on = [\"farm_id\",\"tank_id\", \"feed_dt\"])\n",
    "    japonica_validation_features = pd.merge(left = japonica_validation_sensor_val_tb, right = japonica_validation_food_supply_tb, how = \"left\", left_on = [\"farm_id\",\"tank_id\", \"mea_dt\"], right_on = [\"farm_id\",\"tank_id\", \"feed_dt\"])\n",
    "    japonica_training_features['mea_dt'] = pd.to_datetime(japonica_training_features['mea_dt'], format='%Y-%m-%d %H:%M', errors='raise')\n",
    "    japonica_validation_features['mea_dt'] = pd.to_datetime(japonica_validation_features['mea_dt'], format='%Y-%m-%d %H:%M', errors='raise')\n",
    "    feature_origin = ['tank_id','mea_dt', 'do_mg','do_temp', 'ph', 'orp', 'co2_mg', 'air_oxy', 'light_ma', 'feed_quantity', 'water_quantity']\n",
    "    japonica_training_features = japonica_training_features[feature_origin]\n",
    "    japonica_validation_features = japonica_validation_features[feature_origin]\n",
    "    japonica_training_features = japonica_training_features.fillna(0)\n",
    "    japonica_validation_features = japonica_validation_features.fillna(0)\n",
    "    japonica_training_features.set_index('mea_dt', inplace=True)\n",
    "    japonica_validation_features.set_index('mea_dt', inplace=True)\n",
    "    japonica_training_data = japonica_training_features.sort_index()\n",
    "    japonica_validation_data = japonica_validation_features.sort_index()\n",
    "    japonica_training_data = japonica_training_data.reset_index()\n",
    "    japonica_validation_data = japonica_validation_data.reset_index()\n",
    "    japonica_training_data = japonica_training_data[['do_mg','do_temp', 'ph', 'orp', 'co2_mg', 'air_oxy', 'light_ma', 'feed_quantity', 'water_quantity']]\n",
    "    japonica_validation_data = japonica_validation_data[['do_mg','do_temp', 'ph', 'orp', 'co2_mg', 'air_oxy', 'light_ma', 'feed_quantity', 'water_quantity']]\n",
    "    japonica_training = pd.concat([japonica_training, japonica_training_data])\n",
    "    japonica_validation = pd.concat([japonica_validation, japonica_validation_data])\n",
    "    japonica_training.reset_index(drop=True, inplace=True)\n",
    "    japonica_validation.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10645, 6, 7)\n",
      "(10645, 6, 1)\n",
      "(10645, 6, 7)\n",
      "(10645, 6, 1)\n"
     ]
    }
   ],
   "source": [
    "japonica_training_X = japonica_training[['do_mg','do_temp', 'ph', 'orp', 'co2_mg', 'feed_quantity', 'water_quantity']]\n",
    "japonica_training_y = japonica_training[['do_mg']]\n",
    "japonica_validation_X = japonica_validation[['do_mg','do_temp', 'ph', 'orp', 'co2_mg', 'feed_quantity', 'water_quantity']]\n",
    "japonica_validation_y = japonica_validation[['do_mg']]\n",
    "japonica_training_X_chunks = []\n",
    "japonica_training_y_chunks = []\n",
    "japonica_validation_X_chunks = []\n",
    "japonica_validation_y_chunks = []\n",
    "for i in range(0, len(japonica_training_X) - 5):\n",
    "    japonica_training_X_chunks.append(np.array(japonica_training_X.iloc[i:i+6].values, dtype=np.float64))\n",
    "japonica_training_X_chunks = np.array(japonica_training_X_chunks, dtype=np.float64)\n",
    "for i in range(0, len(japonica_training_y) - 5):\n",
    "    japonica_training_y_chunks.append(np.array(japonica_training_y.iloc[i:i+6].values, dtype=np.float64))\n",
    "japonica_training_y_chunks = np.array(japonica_training_y_chunks, dtype=np.float64)\n",
    "for i in range(0, len(japonica_validation_X) - 5):\n",
    "    japonica_validation_X_chunks.append(np.array(japonica_validation_X.iloc[i:i+6].values, dtype=np.float64))\n",
    "japonica_validation_X_chunks = np.array(japonica_validation_X_chunks, dtype=np.float64)\n",
    "for i in range(0, len(japonica_validation_y) - 5):\n",
    "    japonica_validation_y_chunks.append(np.array(japonica_validation_y.iloc[i:i+6].values, dtype=np.float64))\n",
    "japonica_validation_y_chunks = np.array(japonica_validation_y_chunks, dtype=np.float64)\n",
    "japonica_training_features_X_chunks_crop = japonica_training_X_chunks[:-6]\n",
    "japonica_training_features_y_chunks_crop = japonica_training_y_chunks[6:]\n",
    "japonica_validation_features_X_chunks_crop = japonica_validation_X_chunks[:-6]\n",
    "japonica_validation_features_y_chunks_crop = japonica_validation_y_chunks[6:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rladn\\anaconda3\\envs\\do\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">69,632</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │        <span style=\"color: #00af00; text-decoration-color: #00af00\">49,408</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">12,416</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">198</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │        \u001b[38;5;34m69,632\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │        \u001b[38;5;34m49,408\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │        \u001b[38;5;34m12,416\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)              │           \u001b[38;5;34m198\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">131,654</span> (514.27 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m131,654\u001b[0m (514.27 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">131,654</span> (514.27 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m131,654\u001b[0m (514.27 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 4.3530 - mae: 4.8311 - mse: 32.5015 - val_loss: 0.8298 - val_mae: 1.2265 - val_mse: 2.6966 - learning_rate: 0.0010\n",
      "Epoch 2/1000\n",
      "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.8181 - mae: 1.2134 - mse: 2.6530 - val_loss: 0.8294 - val_mae: 1.2253 - val_mse: 2.6950 - learning_rate: 0.0010\n",
      "Epoch 3/1000\n",
      "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.8239 - mae: 1.2195 - mse: 2.6768 - val_loss: 0.8301 - val_mae: 1.2258 - val_mse: 2.6974 - learning_rate: 0.0010\n",
      "Epoch 4/1000\n",
      "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.8318 - mae: 1.2292 - mse: 2.7147 - val_loss: 0.8295 - val_mae: 1.2253 - val_mse: 2.6951 - learning_rate: 0.0010\n",
      "Epoch 5/1000\n",
      "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.8119 - mae: 1.2080 - mse: 2.6083 - val_loss: 0.5726 - val_mae: 0.9498 - val_mse: 1.6404 - learning_rate: 0.0010\n",
      "Epoch 6/1000\n",
      "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.5106 - mae: 0.8715 - mse: 1.4604 - val_loss: 0.4145 - val_mae: 0.7414 - val_mse: 1.1753 - learning_rate: 0.0010\n",
      "Epoch 7/1000\n",
      "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.4122 - mae: 0.7451 - mse: 1.1564 - val_loss: 0.3927 - val_mae: 0.7210 - val_mse: 1.1112 - learning_rate: 0.0010\n",
      "Epoch 8/1000\n",
      "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.3715 - mae: 0.6894 - mse: 1.0453 - val_loss: 0.3428 - val_mae: 0.6442 - val_mse: 0.9594 - learning_rate: 0.0010\n",
      "Epoch 9/1000\n",
      "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.3438 - mae: 0.6526 - mse: 0.9502 - val_loss: 0.3332 - val_mae: 0.6629 - val_mse: 0.8780 - learning_rate: 0.0010\n",
      "Epoch 10/1000\n",
      "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.3106 - mae: 0.6198 - mse: 0.8155 - val_loss: 0.2904 - val_mae: 0.6116 - val_mse: 0.7398 - learning_rate: 0.0010\n",
      "Epoch 11/1000\n",
      "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.2718 - mae: 0.5690 - mse: 0.6942 - val_loss: 0.2392 - val_mae: 0.5109 - val_mse: 0.6145 - learning_rate: 0.0010\n",
      "Epoch 12/1000\n",
      "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.2645 - mae: 0.5573 - mse: 0.6859 - val_loss: 0.2243 - val_mae: 0.4911 - val_mse: 0.5794 - learning_rate: 0.0010\n",
      "Epoch 13/1000\n",
      "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.2326 - mae: 0.5131 - mse: 0.5977 - val_loss: 0.2149 - val_mae: 0.4791 - val_mse: 0.5523 - learning_rate: 0.0010\n",
      "Epoch 14/1000\n",
      "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.2547 - mae: 0.5510 - mse: 0.6509 - val_loss: 0.2159 - val_mae: 0.4803 - val_mse: 0.5690 - learning_rate: 0.0010\n",
      "Epoch 15/1000\n",
      "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.2257 - mae: 0.5015 - mse: 0.5874 - val_loss: 0.2121 - val_mae: 0.4768 - val_mse: 0.5530 - learning_rate: 0.0010\n",
      "Epoch 16/1000\n",
      "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.2161 - mae: 0.4873 - mse: 0.5589 - val_loss: 0.2200 - val_mae: 0.4881 - val_mse: 0.5842 - learning_rate: 0.0010\n",
      "Epoch 17/1000\n",
      "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.2172 - mae: 0.4878 - mse: 0.5698 - val_loss: 0.2003 - val_mae: 0.4676 - val_mse: 0.5161 - learning_rate: 0.0010\n",
      "Epoch 18/1000\n",
      "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.2107 - mae: 0.4771 - mse: 0.5488 - val_loss: 0.2119 - val_mae: 0.4804 - val_mse: 0.5348 - learning_rate: 0.0010\n",
      "Epoch 19/1000\n",
      "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.2129 - mae: 0.4810 - mse: 0.5600 - val_loss: 0.2038 - val_mae: 0.4708 - val_mse: 0.5369 - learning_rate: 0.0010\n",
      "Epoch 20/1000\n",
      "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.2056 - mae: 0.4717 - mse: 0.5339 - val_loss: 0.1914 - val_mae: 0.4392 - val_mse: 0.5093 - learning_rate: 0.0010\n",
      "Epoch 21/1000\n",
      "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.2083 - mae: 0.4798 - mse: 0.5378 - val_loss: 0.1879 - val_mae: 0.4381 - val_mse: 0.4893 - learning_rate: 0.0010\n",
      "Epoch 22/1000\n",
      "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.1953 - mae: 0.4585 - mse: 0.4993 - val_loss: 0.1866 - val_mae: 0.4312 - val_mse: 0.4869 - learning_rate: 0.0010\n",
      "Epoch 23/1000\n",
      "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.1939 - mae: 0.4505 - mse: 0.5042 - val_loss: 0.2066 - val_mae: 0.4949 - val_mse: 0.5175 - learning_rate: 0.0010\n",
      "Epoch 24/1000\n",
      "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.2017 - mae: 0.4701 - mse: 0.5168 - val_loss: 0.1784 - val_mae: 0.4167 - val_mse: 0.4708 - learning_rate: 0.0010\n",
      "Epoch 25/1000\n",
      "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.1902 - mae: 0.4466 - mse: 0.4951 - val_loss: 0.1856 - val_mae: 0.4527 - val_mse: 0.4772 - learning_rate: 0.0010\n",
      "Epoch 26/1000\n",
      "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.1894 - mae: 0.4473 - mse: 0.4890 - val_loss: 0.1785 - val_mae: 0.4248 - val_mse: 0.4634 - learning_rate: 0.0010\n",
      "Epoch 27/1000\n",
      "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.1848 - mae: 0.4401 - mse: 0.4752 - val_loss: 0.1740 - val_mae: 0.4134 - val_mse: 0.4559 - learning_rate: 0.0010\n",
      "Epoch 28/1000\n",
      "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.1901 - mae: 0.4492 - mse: 0.4873 - val_loss: 0.1848 - val_mae: 0.4361 - val_mse: 0.4900 - learning_rate: 0.0010\n",
      "Epoch 29/1000\n",
      "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.1871 - mae: 0.4403 - mse: 0.4861 - val_loss: 0.1823 - val_mae: 0.4436 - val_mse: 0.4705 - learning_rate: 0.0010\n",
      "Epoch 30/1000\n",
      "\u001b[1m330/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1853 - mae: 0.4367 - mse: 0.4823\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.1853 - mae: 0.4368 - mse: 0.4823 - val_loss: 0.1786 - val_mae: 0.4273 - val_mse: 0.4595 - learning_rate: 0.0010\n",
      "Epoch 31/1000\n",
      "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.1683 - mae: 0.4068 - mse: 0.4341 - val_loss: 0.1660 - val_mae: 0.3976 - val_mse: 0.4384 - learning_rate: 1.0000e-04\n",
      "Epoch 32/1000\n",
      "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.1673 - mae: 0.4021 - mse: 0.4380 - val_loss: 0.1663 - val_mae: 0.4038 - val_mse: 0.4348 - learning_rate: 1.0000e-04\n",
      "Epoch 33/1000\n",
      "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.1690 - mae: 0.4055 - mse: 0.4403 - val_loss: 0.1637 - val_mae: 0.3940 - val_mse: 0.4309 - learning_rate: 1.0000e-04\n",
      "Epoch 34/1000\n",
      "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.1609 - mae: 0.3916 - mse: 0.4246 - val_loss: 0.1634 - val_mae: 0.3962 - val_mse: 0.4281 - learning_rate: 1.0000e-04\n",
      "Epoch 35/1000\n",
      "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.1676 - mae: 0.4026 - mse: 0.4348 - val_loss: 0.1650 - val_mae: 0.4060 - val_mse: 0.4307 - learning_rate: 1.0000e-04\n",
      "Epoch 36/1000\n",
      "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.1631 - mae: 0.3958 - mse: 0.4341 - val_loss: 0.1663 - val_mae: 0.4112 - val_mse: 0.4303 - learning_rate: 1.0000e-04\n",
      "Epoch 37/1000\n",
      "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.1598 - mae: 0.3924 - mse: 0.4125 - val_loss: 0.1621 - val_mae: 0.3908 - val_mse: 0.4273 - learning_rate: 1.0000e-04\n",
      "Epoch 38/1000\n",
      "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.1641 - mae: 0.3942 - mse: 0.4386 - val_loss: 0.1611 - val_mae: 0.3909 - val_mse: 0.4250 - learning_rate: 1.0000e-04\n",
      "Epoch 39/1000\n",
      "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.1618 - mae: 0.3944 - mse: 0.4264 - val_loss: 0.1608 - val_mae: 0.3907 - val_mse: 0.4211 - learning_rate: 1.0000e-04\n",
      "Epoch 40/1000\n",
      "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.1662 - mae: 0.3986 - mse: 0.4453 - val_loss: 0.1608 - val_mae: 0.3921 - val_mse: 0.4210 - learning_rate: 1.0000e-04\n",
      "Epoch 41/1000\n",
      "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.1622 - mae: 0.3933 - mse: 0.4245 - val_loss: 0.1634 - val_mae: 0.3923 - val_mse: 0.4350 - learning_rate: 1.0000e-04\n",
      "Epoch 42/1000\n",
      "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1543 - mae: 0.3833 - mse: 0.4015\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.1543 - mae: 0.3833 - mse: 0.4015 - val_loss: 0.1609 - val_mae: 0.3962 - val_mse: 0.4192 - learning_rate: 1.0000e-04\n",
      "Epoch 43/1000\n",
      "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.1608 - mae: 0.3912 - mse: 0.4255 - val_loss: 0.1592 - val_mae: 0.3904 - val_mse: 0.4166 - learning_rate: 1.0000e-05\n",
      "Epoch 44/1000\n",
      "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.1603 - mae: 0.3912 - mse: 0.4171 - val_loss: 0.1589 - val_mae: 0.3870 - val_mse: 0.4176 - learning_rate: 1.0000e-05\n",
      "Epoch 45/1000\n",
      "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.1575 - mae: 0.3845 - mse: 0.4152 - val_loss: 0.1587 - val_mae: 0.3877 - val_mse: 0.4163 - learning_rate: 1.0000e-05\n",
      "Epoch 46/1000\n",
      "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.1588 - mae: 0.3876 - mse: 0.4120 - val_loss: 0.1587 - val_mae: 0.3872 - val_mse: 0.4164 - learning_rate: 1.0000e-05\n",
      "Epoch 47/1000\n",
      "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.1580 - mae: 0.3877 - mse: 0.4127 - val_loss: 0.1586 - val_mae: 0.3873 - val_mse: 0.4162 - learning_rate: 1.0000e-05\n",
      "Epoch 48/1000\n",
      "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.1659 - mae: 0.3953 - mse: 0.4525 - val_loss: 0.1586 - val_mae: 0.3878 - val_mse: 0.4161 - learning_rate: 1.0000e-05\n",
      "Epoch 49/1000\n",
      "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.1597 - mae: 0.3884 - mse: 0.4198 - val_loss: 0.1592 - val_mae: 0.3913 - val_mse: 0.4167 - learning_rate: 1.0000e-05\n",
      "Epoch 50/1000\n",
      "\u001b[1m331/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1537 - mae: 0.3826 - mse: 0.3946\n",
      "Epoch 50: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.1537 - mae: 0.3827 - mse: 0.3948 - val_loss: 0.1585 - val_mae: 0.3867 - val_mse: 0.4167 - learning_rate: 1.0000e-05\n",
      "Epoch 51/1000\n",
      "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.1580 - mae: 0.3870 - mse: 0.4111 - val_loss: 0.1585 - val_mae: 0.3872 - val_mse: 0.4161 - learning_rate: 1.0000e-06\n",
      "Epoch 52/1000\n",
      "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.1603 - mae: 0.3885 - mse: 0.4287 - val_loss: 0.1585 - val_mae: 0.3869 - val_mse: 0.4162 - learning_rate: 1.0000e-06\n",
      "Epoch 53/1000\n",
      "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.1567 - mae: 0.3827 - mse: 0.4140 - val_loss: 0.1584 - val_mae: 0.3871 - val_mse: 0.4160 - learning_rate: 1.0000e-06\n",
      "Epoch 54/1000\n",
      "\u001b[1m330/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1561 - mae: 0.3831 - mse: 0.4085\n",
      "Epoch 54: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.1561 - mae: 0.3831 - mse: 0.4086 - val_loss: 0.1584 - val_mae: 0.3868 - val_mse: 0.4160 - learning_rate: 1.0000e-06\n",
      "Epoch 55/1000\n",
      "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.1547 - mae: 0.3823 - mse: 0.4048 - val_loss: 0.1584 - val_mae: 0.3869 - val_mse: 0.4160 - learning_rate: 1.0000e-07\n",
      "Epoch 56/1000\n",
      "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.1570 - mae: 0.3851 - mse: 0.4225 - val_loss: 0.1584 - val_mae: 0.3870 - val_mse: 0.4159 - learning_rate: 1.0000e-07\n",
      "Epoch 57/1000\n",
      "\u001b[1m325/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1588 - mae: 0.3874 - mse: 0.4248\n",
      "Epoch 57: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
      "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.1588 - mae: 0.3874 - mse: 0.4245 - val_loss: 0.1584 - val_mae: 0.3870 - val_mse: 0.4159 - learning_rate: 1.0000e-07\n",
      "Epoch 58/1000\n",
      "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.1597 - mae: 0.3890 - mse: 0.4197 - val_loss: 0.1584 - val_mae: 0.3870 - val_mse: 0.4159 - learning_rate: 1.0000e-08\n",
      "Epoch 59/1000\n",
      "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.1609 - mae: 0.3892 - mse: 0.4248 - val_loss: 0.1584 - val_mae: 0.3870 - val_mse: 0.4159 - learning_rate: 1.0000e-08\n",
      "Epoch 60/1000\n",
      "\u001b[1m327/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1639 - mae: 0.3928 - mse: 0.4433\n",
      "Epoch 60: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-09.\n",
      "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.1638 - mae: 0.3927 - mse: 0.4427 - val_loss: 0.1584 - val_mae: 0.3870 - val_mse: 0.4159 - learning_rate: 1.0000e-08\n",
      "Epoch 61/1000\n",
      "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.1606 - mae: 0.3892 - mse: 0.4261 - val_loss: 0.1584 - val_mae: 0.3870 - val_mse: 0.4159 - learning_rate: 1.0000e-09\n",
      "Epoch 62/1000\n",
      "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.1666 - mae: 0.3969 - mse: 0.4429 - val_loss: 0.1584 - val_mae: 0.3870 - val_mse: 0.4159 - learning_rate: 1.0000e-09\n",
      "Epoch 63/1000\n",
      "\u001b[1m326/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1612 - mae: 0.3918 - mse: 0.4165\n",
      "Epoch 63: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-10.\n",
      "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.1611 - mae: 0.3917 - mse: 0.4165 - val_loss: 0.1584 - val_mae: 0.3870 - val_mse: 0.4159 - learning_rate: 1.0000e-09\n",
      "Epoch 64/1000\n",
      "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.1568 - mae: 0.3846 - mse: 0.4075 - val_loss: 0.1584 - val_mae: 0.3870 - val_mse: 0.4159 - learning_rate: 1.0000e-10\n",
      "Epoch 65/1000\n",
      "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.1580 - mae: 0.3878 - mse: 0.4091 - val_loss: 0.1584 - val_mae: 0.3870 - val_mse: 0.4159 - learning_rate: 1.0000e-10\n",
      "Epoch 66/1000\n",
      "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1609 - mae: 0.3897 - mse: 0.4228\n",
      "Epoch 66: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-11.\n",
      "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.1609 - mae: 0.3897 - mse: 0.4227 - val_loss: 0.1584 - val_mae: 0.3870 - val_mse: 0.4159 - learning_rate: 1.0000e-10\n",
      "Epoch 67/1000\n",
      "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.1541 - mae: 0.3819 - mse: 0.3981 - val_loss: 0.1584 - val_mae: 0.3870 - val_mse: 0.4159 - learning_rate: 1.0000e-11\n",
      "Epoch 68/1000\n",
      "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.1592 - mae: 0.3881 - mse: 0.4230 - val_loss: 0.1584 - val_mae: 0.3870 - val_mse: 0.4159 - learning_rate: 1.0000e-11\n",
      "Epoch 68: early stopping\n"
     ]
    }
   ],
   "source": [
    "huber_loss = Huber(delta=1.0)\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(6, 7), return_sequences=True))\n",
    "model.add(LSTM(64, return_sequences=True))\n",
    "model.add(LSTM(32))\n",
    "model.add(Dense(6, activation='linear'))\n",
    "model.summary()\n",
    "model.compile(optimizer='adam', loss=huber_loss, metrics=['mse','mae'])\n",
    "checkpoint = ModelCheckpoint(model_name + '_best.keras', monitor='val_loss', save_best_only=True)\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, verbose=1)\n",
    "hist = model.fit(japonica_training_features_X_chunks_crop, japonica_training_features_y_chunks_crop, epochs = 1000, batch_size = 32, validation_data=(japonica_validation_features_X_chunks_crop, japonica_validation_features_y_chunks_crop), callbacks=[checkpoint, early_stop, reduce_lr])\n",
    "model.save(model_name+'.keras')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "doRegressor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
