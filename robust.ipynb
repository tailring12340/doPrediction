{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "라이브러리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.utils import *\n",
    "from keras.layers import LSTM, Dense, TimeDistributed\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from sklearn.preprocessing import *\n",
    "from keras.losses import Huber\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "model_name = 'model/Aqua_all_robust'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "japonica_training = pd.DataFrame()\n",
    "japonica_validation = pd.DataFrame()\n",
    "for i in range(5):\n",
    "    tank = i + 1\n",
    "    japonica_training_food_supply_tb = pd.read_csv(\"dataset/japonica_training_food_supply_tb.csv\")\n",
    "    japonica_training_sensor_val_tb = pd.read_csv(\"dataset/japonica_training_sensor_val_tb.csv\")\n",
    "    japonica_validation_food_supply_tb = pd.read_csv(\"dataset/japonica_validation_food_supply_tb.csv\")\n",
    "    japonica_validation_sensor_val_tb = pd.read_csv(\"dataset/japonica_validation_sensor_val_tb.csv\")\n",
    "    japonica_training_food_supply_tb = japonica_training_food_supply_tb[japonica_training_food_supply_tb['tank_id']==tank]\n",
    "    japonica_validation_food_supply_tb = japonica_validation_food_supply_tb[japonica_validation_food_supply_tb['tank_id']==tank]\n",
    "    japonica_training_food_supply_tb = japonica_training_food_supply_tb[japonica_training_food_supply_tb['feed_quantity'].notnull()]\n",
    "    japonica_validation_food_supply_tb = japonica_validation_food_supply_tb[japonica_validation_food_supply_tb['feed_quantity'].notnull()]\n",
    "    japonica_training_food_supply_tb['feed_dt'] = pd.to_datetime(japonica_training_food_supply_tb['feed_dt'], format='%Y%m%d%H%M', errors='raise')\n",
    "    japonica_training_food_supply_tb[\"feed_dt\"] = japonica_training_food_supply_tb[\"feed_dt\"].apply(str)\n",
    "    japonica_training_food_supply_tb[\"feed_dt\"] = japonica_training_food_supply_tb[\"feed_dt\"].str.slice(start=0, stop=16)\n",
    "    japonica_validation_food_supply_tb['feed_dt'] = pd.to_datetime(japonica_validation_food_supply_tb['feed_dt'], format='%Y%m%d%H%M', errors='raise')\n",
    "    japonica_validation_food_supply_tb[\"feed_dt\"] = japonica_validation_food_supply_tb[\"feed_dt\"].apply(str)\n",
    "    japonica_validation_food_supply_tb[\"feed_dt\"] = japonica_validation_food_supply_tb[\"feed_dt\"].str.slice(start=0, stop=16)\n",
    "    japonica_training_sensor_val_tb = japonica_training_sensor_val_tb[japonica_training_sensor_val_tb['tank_id']==tank]\n",
    "    japonica_validation_sensor_val_tb = japonica_validation_sensor_val_tb[japonica_validation_sensor_val_tb['tank_id']==tank]\n",
    "    japonica_training_sensor_val_tb[\"mea_dt\"] = japonica_training_sensor_val_tb[\"mea_dt\"].apply(str)\n",
    "    japonica_training_sensor_val_tb[\"mea_dt\"] = japonica_training_sensor_val_tb[\"mea_dt\"].str.slice(start=0, stop=16)\n",
    "    japonica_training_sensor_val_tb['mea_dt'] = pd.to_datetime(japonica_training_sensor_val_tb['mea_dt'], format='%Y-%m-%d %H:%M', errors='raise')\n",
    "    japonica_validation_sensor_val_tb[\"mea_dt\"] = japonica_validation_sensor_val_tb[\"mea_dt\"].apply(str)\n",
    "    japonica_validation_sensor_val_tb[\"mea_dt\"] = japonica_validation_sensor_val_tb[\"mea_dt\"].str.slice(start=0, stop=16)\n",
    "    japonica_validation_sensor_val_tb['mea_dt'] = pd.to_datetime(japonica_validation_sensor_val_tb['mea_dt'], format='%Y-%m-%d %H:%M', errors='raise')\n",
    "    japonica_training_sensor_val_tb['date'] = pd.to_datetime(japonica_training_sensor_val_tb['mea_dt']).dt.date\n",
    "    japonica_training_food_supply_tb['date'] = pd.to_datetime(japonica_training_food_supply_tb['feed_dt']).dt.date\n",
    "    common_dates = japonica_training_sensor_val_tb['date'].isin(japonica_training_food_supply_tb['date'])\n",
    "    japonica_training_sensor_val_tb = japonica_training_sensor_val_tb[common_dates]\n",
    "    japonica_training_sensor_val_tb = japonica_training_sensor_val_tb.drop('date', axis=1)\n",
    "    japonica_validation_sensor_val_tb['date'] = pd.to_datetime(japonica_validation_sensor_val_tb['mea_dt']).dt.date\n",
    "    japonica_validation_food_supply_tb['date'] = pd.to_datetime(japonica_validation_food_supply_tb['feed_dt']).dt.date\n",
    "    common_dates = japonica_validation_sensor_val_tb['date'].isin(japonica_validation_food_supply_tb['date'])\n",
    "    japonica_validation_sensor_val_tb = japonica_validation_sensor_val_tb[common_dates]\n",
    "    japonica_validation_sensor_val_tb = japonica_validation_sensor_val_tb.drop('date', axis=1)\n",
    "    japonica_training_sensor_val_tb.set_index('mea_dt', inplace=True)\n",
    "    japonica_training_sensor_val_tb = japonica_training_sensor_val_tb.resample('30min').mean()\n",
    "    japonica_training_sensor_val_tb = japonica_training_sensor_val_tb.reset_index()\n",
    "    japonica_training_sensor_val_tb = japonica_training_sensor_val_tb.dropna()\n",
    "    japonica_validation_sensor_val_tb.set_index('mea_dt', inplace=True)\n",
    "    japonica_validation_sensor_val_tb = japonica_validation_sensor_val_tb.resample('30min').mean()\n",
    "    japonica_validation_sensor_val_tb = japonica_validation_sensor_val_tb.reset_index()\n",
    "    japonica_validation_sensor_val_tb = japonica_validation_sensor_val_tb.dropna()\n",
    "    training_counts = japonica_training_sensor_val_tb.groupby(japonica_training_sensor_val_tb['mea_dt'].dt.date).size()\n",
    "    validation_counts = japonica_validation_sensor_val_tb.groupby(japonica_validation_sensor_val_tb['mea_dt'].dt.date).size()\n",
    "    to_delete = training_counts[training_counts != 48].index\n",
    "    japonica_training_sensor_val_tb = japonica_training_sensor_val_tb[~japonica_training_sensor_val_tb['mea_dt'].dt.date.isin(to_delete)]\n",
    "    to_delete = validation_counts[validation_counts != 48].index\n",
    "    japonica_validation_sensor_val_tb = japonica_validation_sensor_val_tb[~japonica_validation_sensor_val_tb['mea_dt'].dt.date.isin(to_delete)]\n",
    "    japonica_training_sensor_val_tb[\"mea_dt\"] = japonica_training_sensor_val_tb[\"mea_dt\"].dt.strftime('%Y-%m-%d %H:%M')\n",
    "    japonica_training_sensor_val_tb[\"mea_dt\"] = japonica_training_sensor_val_tb[\"mea_dt\"].str.slice(start=0, stop=16)\n",
    "    japonica_validation_sensor_val_tb[\"mea_dt\"] = japonica_validation_sensor_val_tb[\"mea_dt\"].dt.strftime('%Y-%m-%d %H:%M')\n",
    "    japonica_validation_sensor_val_tb[\"mea_dt\"] = japonica_validation_sensor_val_tb[\"mea_dt\"].str.slice(start=0, stop=16)\n",
    "    japonica_training_features = pd.merge(left = japonica_training_sensor_val_tb, right = japonica_training_food_supply_tb, how = \"left\", left_on = [\"farm_id\",\"tank_id\", \"mea_dt\"], right_on = [\"farm_id\",\"tank_id\", \"feed_dt\"])\n",
    "    japonica_validation_features = pd.merge(left = japonica_validation_sensor_val_tb, right = japonica_validation_food_supply_tb, how = \"left\", left_on = [\"farm_id\",\"tank_id\", \"mea_dt\"], right_on = [\"farm_id\",\"tank_id\", \"feed_dt\"])\n",
    "    japonica_training_features['mea_dt'] = pd.to_datetime(japonica_training_features['mea_dt'], format='%Y-%m-%d %H:%M', errors='raise')\n",
    "    japonica_validation_features['mea_dt'] = pd.to_datetime(japonica_validation_features['mea_dt'], format='%Y-%m-%d %H:%M', errors='raise')\n",
    "    feature_origin = ['tank_id','mea_dt', 'do_mg','do_temp', 'ph', 'orp', 'co2_mg', 'air_oxy', 'light_ma', 'feed_quantity', 'water_quantity']\n",
    "    japonica_training_features = japonica_training_features[feature_origin]\n",
    "    japonica_validation_features = japonica_validation_features[feature_origin]\n",
    "    japonica_training_features = japonica_training_features.fillna(0)\n",
    "    japonica_validation_features = japonica_validation_features.fillna(0)\n",
    "    japonica_training_features.set_index('mea_dt', inplace=True)\n",
    "    japonica_validation_features.set_index('mea_dt', inplace=True)\n",
    "    japonica_training_data = japonica_training_features.sort_index()\n",
    "    japonica_validation_data = japonica_validation_features.sort_index()\n",
    "    japonica_training_data = japonica_training_data.reset_index()\n",
    "    japonica_validation_data = japonica_validation_data.reset_index()\n",
    "    japonica_training_data = japonica_training_data[['do_mg','do_temp', 'ph', 'orp', 'co2_mg', 'feed_quantity', 'water_quantity']]\n",
    "    japonica_validation_data = japonica_validation_data[['do_mg','do_temp', 'ph', 'orp', 'co2_mg', 'feed_quantity', 'water_quantity']]\n",
    "    japonica_training = pd.concat([japonica_training, japonica_training_data])\n",
    "    japonica_validation = pd.concat([japonica_validation, japonica_validation_data])\n",
    "    japonica_training.reset_index(drop=True, inplace=True)\n",
    "    japonica_validation.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = RobustScaler()\n",
    "train_standardized = scaler.fit_transform(japonica_training)\n",
    "japonica_training_standard = pd.DataFrame(train_standardized, columns=japonica_training.columns, index=japonica_training.index)\n",
    "test_standardized = scaler.fit_transform(japonica_validation)\n",
    "japonica_validation_standard = pd.DataFrame(test_standardized, columns=japonica_validation.columns, index=japonica_validation.index)\n",
    "japonica_training_features_X = japonica_training_standard.copy()\n",
    "japonica_training_features_y = japonica_training_standard.copy()\n",
    "japonica_validation_features_X = japonica_validation_standard.copy()\n",
    "japonica_validation_features_y = japonica_validation_standard.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10645, 6, 7)\n",
      "(10645, 6, 7)\n",
      "(10645, 6, 7)\n",
      "(10645, 6, 7)\n"
     ]
    }
   ],
   "source": [
    "japonica_training_features_X_chunks = []\n",
    "japonica_training_features_y_chunks = []\n",
    "japonica_validation_features_X_chunks = []\n",
    "japonica_validation_features_y_chunks = []\n",
    "for i in range(0, len(japonica_training_features_X) - 5):\n",
    "    japonica_training_features_X_chunks.append(np.array(japonica_training_features_X.iloc[i:i+6].values, dtype=np.float64))\n",
    "japonica_training_features_X_chunks = np.array(japonica_training_features_X_chunks, dtype=np.float64)\n",
    "for i in range(0, len(japonica_training_features_y) - 5):\n",
    "    japonica_training_features_y_chunks.append(np.array(japonica_training_features_y.iloc[i:i+6].values, dtype=np.float64))\n",
    "japonica_training_features_y_chunks = np.array(japonica_training_features_y_chunks, dtype=np.float64)\n",
    "for i in range(0, len(japonica_validation_features_X) - 5):\n",
    "    japonica_validation_features_X_chunks.append(np.array(japonica_validation_features_X.iloc[i:i+6].values, dtype=np.float64))\n",
    "japonica_validation_features_X_chunks = np.array(japonica_validation_features_X_chunks, dtype=np.float64)\n",
    "for i in range(0, len(japonica_validation_features_y) - 5):\n",
    "    japonica_validation_features_y_chunks.append(np.array(japonica_validation_features_y.iloc[i:i+6].values, dtype=np.float64))\n",
    "japonica_validation_features_y_chunks = np.array(japonica_validation_features_y_chunks, dtype=np.float64)\n",
    "japonica_training_features_X_chunks_crop = japonica_training_features_X_chunks[:-6]\n",
    "japonica_training_features_y_chunks_crop = japonica_training_features_y_chunks[6:]\n",
    "japonica_validation_features_X_chunks_crop = japonica_validation_features_X_chunks[:-6]\n",
    "japonica_validation_features_y_chunks_crop = japonica_validation_features_y_chunks[6:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rladn\\anaconda3\\envs\\do\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">69,632</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │        <span style=\"color: #00af00; text-decoration-color: #00af00\">49,408</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │        <span style=\"color: #00af00; text-decoration-color: #00af00\">12,416</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)           │           <span style=\"color: #00af00; text-decoration-color: #00af00\">231</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │        \u001b[38;5;34m69,632\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │        \u001b[38;5;34m49,408\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │        \u001b[38;5;34m12,416\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m7\u001b[0m)           │           \u001b[38;5;34m231\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">131,687</span> (514.40 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m131,687\u001b[0m (514.40 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">131,687</span> (514.40 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m131,687\u001b[0m (514.40 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - loss: 0.2876 - mae: 0.4713 - mse: 2.9193 - val_loss: 0.1885 - val_mae: 0.3280 - val_mse: 2.3387 - learning_rate: 0.0010\n",
      "Epoch 2/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - loss: 0.1910 - mae: 0.3250 - mse: 2.3791 - val_loss: 0.1812 - val_mae: 0.3073 - val_mse: 2.3226 - learning_rate: 0.0010\n",
      "Epoch 3/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - loss: 0.1843 - mae: 0.3112 - mse: 2.3705 - val_loss: 0.1807 - val_mae: 0.3066 - val_mse: 2.3228 - learning_rate: 0.0010\n",
      "Epoch 4/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - loss: 0.1793 - mae: 0.3034 - mse: 2.3073 - val_loss: 0.1805 - val_mae: 0.3043 - val_mse: 2.3203 - learning_rate: 0.0010\n",
      "Epoch 5/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - loss: 0.1730 - mae: 0.2926 - mse: 2.2569 - val_loss: 0.1742 - val_mae: 0.2903 - val_mse: 2.3022 - learning_rate: 0.0010\n",
      "Epoch 6/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - loss: 0.1789 - mae: 0.2986 - mse: 2.3479 - val_loss: 0.1743 - val_mae: 0.2897 - val_mse: 2.3014 - learning_rate: 0.0010\n",
      "Epoch 7/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - loss: 0.1750 - mae: 0.2917 - mse: 2.3288 - val_loss: 0.1723 - val_mae: 0.2888 - val_mse: 2.2936 - learning_rate: 0.0010\n",
      "Epoch 8/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - loss: 0.1733 - mae: 0.2898 - mse: 2.2769 - val_loss: 0.1710 - val_mae: 0.2821 - val_mse: 2.2887 - learning_rate: 0.0010\n",
      "Epoch 9/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 8ms/step - loss: 0.1670 - mae: 0.2804 - mse: 2.2193 - val_loss: 0.1703 - val_mae: 0.2839 - val_mse: 2.2866 - learning_rate: 0.0010\n",
      "Epoch 10/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - loss: 0.1697 - mae: 0.2836 - mse: 2.2723 - val_loss: 0.1689 - val_mae: 0.2857 - val_mse: 2.2751 - learning_rate: 0.0010\n",
      "Epoch 11/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 8ms/step - loss: 0.1666 - mae: 0.2781 - mse: 2.2486 - val_loss: 0.1695 - val_mae: 0.2814 - val_mse: 2.2801 - learning_rate: 0.0010\n",
      "Epoch 12/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - loss: 0.1716 - mae: 0.2834 - mse: 2.3181 - val_loss: 0.1669 - val_mae: 0.2789 - val_mse: 2.2667 - learning_rate: 0.0010\n",
      "Epoch 13/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - loss: 0.1676 - mae: 0.2776 - mse: 2.2809 - val_loss: 0.1657 - val_mae: 0.2732 - val_mse: 2.2637 - learning_rate: 0.0010\n",
      "Epoch 14/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - loss: 0.1645 - mae: 0.2728 - mse: 2.2358 - val_loss: 0.1650 - val_mae: 0.2729 - val_mse: 2.2615 - learning_rate: 0.0010\n",
      "Epoch 15/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - loss: 0.1667 - mae: 0.2739 - mse: 2.2939 - val_loss: 0.1647 - val_mae: 0.2706 - val_mse: 2.2583 - learning_rate: 0.0010\n",
      "Epoch 16/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 8ms/step - loss: 0.1674 - mae: 0.2745 - mse: 2.2949 - val_loss: 0.1634 - val_mae: 0.2680 - val_mse: 2.2505 - learning_rate: 0.0010\n",
      "Epoch 17/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - loss: 0.1653 - mae: 0.2710 - mse: 2.2835 - val_loss: 0.1633 - val_mae: 0.2694 - val_mse: 2.2430 - learning_rate: 0.0010\n",
      "Epoch 18/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - loss: 0.1617 - mae: 0.2667 - mse: 2.2091 - val_loss: 0.1627 - val_mae: 0.2667 - val_mse: 2.2347 - learning_rate: 0.0010\n",
      "Epoch 19/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - loss: 0.1607 - mae: 0.2647 - mse: 2.2135 - val_loss: 0.1624 - val_mae: 0.2640 - val_mse: 2.2338 - learning_rate: 0.0010\n",
      "Epoch 20/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - loss: 0.1620 - mae: 0.2649 - mse: 2.2092 - val_loss: 0.1611 - val_mae: 0.2669 - val_mse: 2.2141 - learning_rate: 0.0010\n",
      "Epoch 21/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - loss: 0.1649 - mae: 0.2687 - mse: 2.2763 - val_loss: 0.1606 - val_mae: 0.2637 - val_mse: 2.2059 - learning_rate: 0.0010\n",
      "Epoch 22/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - loss: 0.1532 - mae: 0.2546 - mse: 2.0941 - val_loss: 0.1605 - val_mae: 0.2616 - val_mse: 2.2007 - learning_rate: 0.0010\n",
      "Epoch 23/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - loss: 0.1592 - mae: 0.2617 - mse: 2.1563 - val_loss: 0.1584 - val_mae: 0.2567 - val_mse: 2.1975 - learning_rate: 0.0010\n",
      "Epoch 24/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - loss: 0.1588 - mae: 0.2604 - mse: 2.1641 - val_loss: 0.1583 - val_mae: 0.2594 - val_mse: 2.1651 - learning_rate: 0.0010\n",
      "Epoch 25/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - loss: 0.1582 - mae: 0.2593 - mse: 2.1820 - val_loss: 0.1582 - val_mae: 0.2597 - val_mse: 2.1621 - learning_rate: 0.0010\n",
      "Epoch 26/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - loss: 0.1556 - mae: 0.2571 - mse: 2.1035 - val_loss: 0.1568 - val_mae: 0.2595 - val_mse: 2.1118 - learning_rate: 0.0010\n",
      "Epoch 27/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - loss: 0.1549 - mae: 0.2557 - mse: 2.0997 - val_loss: 0.1560 - val_mae: 0.2568 - val_mse: 2.1216 - learning_rate: 0.0010\n",
      "Epoch 28/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - loss: 0.1524 - mae: 0.2536 - mse: 2.0537 - val_loss: 0.1541 - val_mae: 0.2532 - val_mse: 2.0834 - learning_rate: 0.0010\n",
      "Epoch 29/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 8ms/step - loss: 0.1557 - mae: 0.2575 - mse: 2.1020 - val_loss: 0.1541 - val_mae: 0.2564 - val_mse: 2.0133 - learning_rate: 0.0010\n",
      "Epoch 30/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - loss: 0.1530 - mae: 0.2557 - mse: 2.0365 - val_loss: 0.1537 - val_mae: 0.2570 - val_mse: 1.9939 - learning_rate: 0.0010\n",
      "Epoch 31/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - loss: 0.1502 - mae: 0.2531 - mse: 1.9899 - val_loss: 0.1528 - val_mae: 0.2597 - val_mse: 2.0195 - learning_rate: 0.0010\n",
      "Epoch 32/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - loss: 0.1547 - mae: 0.2594 - mse: 2.0475 - val_loss: 0.1492 - val_mae: 0.2530 - val_mse: 1.9565 - learning_rate: 0.0010\n",
      "Epoch 33/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - loss: 0.1478 - mae: 0.2523 - mse: 1.9239 - val_loss: 0.1443 - val_mae: 0.2484 - val_mse: 1.8874 - learning_rate: 0.0010\n",
      "Epoch 34/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - loss: 0.1476 - mae: 0.2535 - mse: 1.9148 - val_loss: 0.1432 - val_mae: 0.2465 - val_mse: 1.8824 - learning_rate: 0.0010\n",
      "Epoch 35/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - loss: 0.1490 - mae: 0.2545 - mse: 1.9516 - val_loss: 0.1447 - val_mae: 0.2479 - val_mse: 1.8974 - learning_rate: 0.0010\n",
      "Epoch 36/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - loss: 0.1410 - mae: 0.2462 - mse: 1.8421 - val_loss: 0.1440 - val_mae: 0.2514 - val_mse: 1.8646 - learning_rate: 0.0010\n",
      "Epoch 37/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - loss: 0.1454 - mae: 0.2505 - mse: 1.9174 - val_loss: 0.1404 - val_mae: 0.2458 - val_mse: 1.8452 - learning_rate: 0.0010\n",
      "Epoch 38/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - loss: 0.1461 - mae: 0.2509 - mse: 1.9317 - val_loss: 0.1440 - val_mae: 0.2490 - val_mse: 1.8819 - learning_rate: 0.0010\n",
      "Epoch 39/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - loss: 0.1455 - mae: 0.2497 - mse: 1.9181 - val_loss: 0.1421 - val_mae: 0.2472 - val_mse: 1.8777 - learning_rate: 0.0010\n",
      "Epoch 40/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - loss: 0.1375 - mae: 0.2409 - mse: 1.8215 - val_loss: 0.1402 - val_mae: 0.2409 - val_mse: 1.8559 - learning_rate: 0.0010\n",
      "Epoch 41/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - loss: 0.1374 - mae: 0.2397 - mse: 1.8024 - val_loss: 0.1382 - val_mae: 0.2383 - val_mse: 1.8333 - learning_rate: 0.0010\n",
      "Epoch 42/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - loss: 0.1411 - mae: 0.2437 - mse: 1.8692 - val_loss: 0.1344 - val_mae: 0.2351 - val_mse: 1.7940 - learning_rate: 0.0010\n",
      "Epoch 43/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - loss: 0.1337 - mae: 0.2346 - mse: 1.7654 - val_loss: 0.1359 - val_mae: 0.2368 - val_mse: 1.8004 - learning_rate: 0.0010\n",
      "Epoch 44/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - loss: 0.1375 - mae: 0.2392 - mse: 1.8183 - val_loss: 0.1334 - val_mae: 0.2349 - val_mse: 1.7476 - learning_rate: 0.0010\n",
      "Epoch 45/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - loss: 0.1323 - mae: 0.2340 - mse: 1.7014 - val_loss: 0.1355 - val_mae: 0.2368 - val_mse: 1.7823 - learning_rate: 0.0010\n",
      "Epoch 46/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - loss: 0.1413 - mae: 0.2442 - mse: 1.8638 - val_loss: 0.1325 - val_mae: 0.2321 - val_mse: 1.7659 - learning_rate: 0.0010\n",
      "Epoch 47/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - loss: 0.1328 - mae: 0.2329 - mse: 1.7577 - val_loss: 0.1326 - val_mae: 0.2338 - val_mse: 1.7398 - learning_rate: 0.0010\n",
      "Epoch 48/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - loss: 0.1304 - mae: 0.2306 - mse: 1.7079 - val_loss: 0.1316 - val_mae: 0.2317 - val_mse: 1.7467 - learning_rate: 0.0010\n",
      "Epoch 49/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - loss: 0.1359 - mae: 0.2363 - mse: 1.7991 - val_loss: 0.1303 - val_mae: 0.2298 - val_mse: 1.7316 - learning_rate: 0.0010\n",
      "Epoch 50/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 8ms/step - loss: 0.1308 - mae: 0.2304 - mse: 1.7301 - val_loss: 0.1319 - val_mae: 0.2319 - val_mse: 1.7322 - learning_rate: 0.0010\n",
      "Epoch 51/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - loss: 0.1258 - mae: 0.2251 - mse: 1.6414 - val_loss: 0.1300 - val_mae: 0.2306 - val_mse: 1.7068 - learning_rate: 0.0010\n",
      "Epoch 52/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - loss: 0.1347 - mae: 0.2343 - mse: 1.7762 - val_loss: 0.1296 - val_mae: 0.2269 - val_mse: 1.7320 - learning_rate: 0.0010\n",
      "Epoch 53/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - loss: 0.1343 - mae: 0.2339 - mse: 1.7882 - val_loss: 0.1273 - val_mae: 0.2249 - val_mse: 1.6867 - learning_rate: 0.0010\n",
      "Epoch 54/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - loss: 0.1287 - mae: 0.2278 - mse: 1.6767 - val_loss: 0.1311 - val_mae: 0.2291 - val_mse: 1.7511 - learning_rate: 0.0010\n",
      "Epoch 55/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - loss: 0.1307 - mae: 0.2300 - mse: 1.7119 - val_loss: 0.1278 - val_mae: 0.2258 - val_mse: 1.6837 - learning_rate: 0.0010\n",
      "Epoch 56/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1250 - mae: 0.2239 - mse: 1.6387\n",
      "Epoch 56: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - loss: 0.1250 - mae: 0.2239 - mse: 1.6387 - val_loss: 0.1294 - val_mae: 0.2290 - val_mse: 1.6904 - learning_rate: 0.0010\n",
      "Epoch 57/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - loss: 0.1262 - mae: 0.2229 - mse: 1.6588 - val_loss: 0.1198 - val_mae: 0.2128 - val_mse: 1.5967 - learning_rate: 1.0000e-04\n",
      "Epoch 58/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - loss: 0.1219 - mae: 0.2150 - mse: 1.6307 - val_loss: 0.1178 - val_mae: 0.2102 - val_mse: 1.5679 - learning_rate: 1.0000e-04\n",
      "Epoch 59/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - loss: 0.1203 - mae: 0.2128 - mse: 1.6041 - val_loss: 0.1163 - val_mae: 0.2074 - val_mse: 1.5463 - learning_rate: 1.0000e-04\n",
      "Epoch 60/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - loss: 0.1163 - mae: 0.2082 - mse: 1.5550 - val_loss: 0.1153 - val_mae: 0.2067 - val_mse: 1.5282 - learning_rate: 1.0000e-04\n",
      "Epoch 61/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - loss: 0.1142 - mae: 0.2059 - mse: 1.5040 - val_loss: 0.1144 - val_mae: 0.2056 - val_mse: 1.5173 - learning_rate: 1.0000e-04\n",
      "Epoch 62/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - loss: 0.1178 - mae: 0.2093 - mse: 1.5697 - val_loss: 0.1137 - val_mae: 0.2045 - val_mse: 1.5081 - learning_rate: 1.0000e-04\n",
      "Epoch 63/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - loss: 0.1171 - mae: 0.2083 - mse: 1.5553 - val_loss: 0.1126 - val_mae: 0.2033 - val_mse: 1.4861 - learning_rate: 1.0000e-04\n",
      "Epoch 64/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - loss: 0.1139 - mae: 0.2051 - mse: 1.5063 - val_loss: 0.1119 - val_mae: 0.2024 - val_mse: 1.4814 - learning_rate: 1.0000e-04\n",
      "Epoch 65/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - loss: 0.1109 - mae: 0.2018 - mse: 1.4592 - val_loss: 0.1116 - val_mae: 0.2022 - val_mse: 1.4765 - learning_rate: 1.0000e-04\n",
      "Epoch 66/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - loss: 0.1118 - mae: 0.2029 - mse: 1.4643 - val_loss: 0.1111 - val_mae: 0.2014 - val_mse: 1.4696 - learning_rate: 1.0000e-04\n",
      "Epoch 67/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - loss: 0.1085 - mae: 0.1991 - mse: 1.4286 - val_loss: 0.1105 - val_mae: 0.2012 - val_mse: 1.4585 - learning_rate: 1.0000e-04\n",
      "Epoch 68/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - loss: 0.1065 - mae: 0.1968 - mse: 1.3991 - val_loss: 0.1100 - val_mae: 0.2004 - val_mse: 1.4555 - learning_rate: 1.0000e-04\n",
      "Epoch 69/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - loss: 0.1101 - mae: 0.2008 - mse: 1.4461 - val_loss: 0.1098 - val_mae: 0.1999 - val_mse: 1.4521 - learning_rate: 1.0000e-04\n",
      "Epoch 70/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - loss: 0.1135 - mae: 0.2045 - mse: 1.5006 - val_loss: 0.1097 - val_mae: 0.1999 - val_mse: 1.4474 - learning_rate: 1.0000e-04\n",
      "Epoch 71/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - loss: 0.1078 - mae: 0.1978 - mse: 1.4078 - val_loss: 0.1090 - val_mae: 0.1994 - val_mse: 1.4382 - learning_rate: 1.0000e-04\n",
      "Epoch 72/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - loss: 0.1120 - mae: 0.2024 - mse: 1.4918 - val_loss: 0.1089 - val_mae: 0.1991 - val_mse: 1.4370 - learning_rate: 1.0000e-04\n",
      "Epoch 73/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - loss: 0.1082 - mae: 0.1984 - mse: 1.4336 - val_loss: 0.1085 - val_mae: 0.1985 - val_mse: 1.4303 - learning_rate: 1.0000e-04\n",
      "Epoch 74/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - loss: 0.1073 - mae: 0.1973 - mse: 1.4118 - val_loss: 0.1080 - val_mae: 0.1978 - val_mse: 1.4242 - learning_rate: 1.0000e-04\n",
      "Epoch 75/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - loss: 0.1076 - mae: 0.1979 - mse: 1.3969 - val_loss: 0.1076 - val_mae: 0.1973 - val_mse: 1.4162 - learning_rate: 1.0000e-04\n",
      "Epoch 76/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 9ms/step - loss: 0.1062 - mae: 0.1960 - mse: 1.3908 - val_loss: 0.1073 - val_mae: 0.1971 - val_mse: 1.4145 - learning_rate: 1.0000e-04\n",
      "Epoch 77/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - loss: 0.1083 - mae: 0.1983 - mse: 1.4290 - val_loss: 0.1069 - val_mae: 0.1967 - val_mse: 1.4073 - learning_rate: 1.0000e-04\n",
      "Epoch 78/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - loss: 0.1091 - mae: 0.1991 - mse: 1.4441 - val_loss: 0.1068 - val_mae: 0.1968 - val_mse: 1.4016 - learning_rate: 1.0000e-04\n",
      "Epoch 79/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - loss: 0.1103 - mae: 0.2013 - mse: 1.4538 - val_loss: 0.1065 - val_mae: 0.1968 - val_mse: 1.3957 - learning_rate: 1.0000e-04\n",
      "Epoch 80/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - loss: 0.1098 - mae: 0.2002 - mse: 1.4633 - val_loss: 0.1063 - val_mae: 0.1959 - val_mse: 1.3965 - learning_rate: 1.0000e-04\n",
      "Epoch 81/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - loss: 0.1095 - mae: 0.2000 - mse: 1.4382 - val_loss: 0.1059 - val_mae: 0.1956 - val_mse: 1.3928 - learning_rate: 1.0000e-04\n",
      "Epoch 82/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - loss: 0.1047 - mae: 0.1949 - mse: 1.3557 - val_loss: 0.1058 - val_mae: 0.1953 - val_mse: 1.3861 - learning_rate: 1.0000e-04\n",
      "Epoch 83/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - loss: 0.1068 - mae: 0.1967 - mse: 1.4055 - val_loss: 0.1055 - val_mae: 0.1953 - val_mse: 1.3790 - learning_rate: 1.0000e-04\n",
      "Epoch 84/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 8ms/step - loss: 0.1044 - mae: 0.1946 - mse: 1.3432 - val_loss: 0.1050 - val_mae: 0.1950 - val_mse: 1.3768 - learning_rate: 1.0000e-04\n",
      "Epoch 85/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - loss: 0.1053 - mae: 0.1953 - mse: 1.3790 - val_loss: 0.1048 - val_mae: 0.1946 - val_mse: 1.3734 - learning_rate: 1.0000e-04\n",
      "Epoch 86/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - loss: 0.1041 - mae: 0.1945 - mse: 1.3552 - val_loss: 0.1046 - val_mae: 0.1948 - val_mse: 1.3631 - learning_rate: 1.0000e-04\n",
      "Epoch 87/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - loss: 0.1041 - mae: 0.1942 - mse: 1.3495 - val_loss: 0.1039 - val_mae: 0.1938 - val_mse: 1.3634 - learning_rate: 1.0000e-04\n",
      "Epoch 88/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - loss: 0.1014 - mae: 0.1911 - mse: 1.3150 - val_loss: 0.1036 - val_mae: 0.1935 - val_mse: 1.3562 - learning_rate: 1.0000e-04\n",
      "Epoch 89/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - loss: 0.1053 - mae: 0.1956 - mse: 1.3811 - val_loss: 0.1034 - val_mae: 0.1935 - val_mse: 1.3495 - learning_rate: 1.0000e-04\n",
      "Epoch 90/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - loss: 0.1017 - mae: 0.1917 - mse: 1.3097 - val_loss: 0.1031 - val_mae: 0.1927 - val_mse: 1.3504 - learning_rate: 1.0000e-04\n",
      "Epoch 91/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - loss: 0.1034 - mae: 0.1937 - mse: 1.3454 - val_loss: 0.1028 - val_mae: 0.1923 - val_mse: 1.3507 - learning_rate: 1.0000e-04\n",
      "Epoch 92/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - loss: 0.1024 - mae: 0.1917 - mse: 1.3433 - val_loss: 0.1026 - val_mae: 0.1920 - val_mse: 1.3453 - learning_rate: 1.0000e-04\n",
      "Epoch 93/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - loss: 0.1044 - mae: 0.1944 - mse: 1.3677 - val_loss: 0.1025 - val_mae: 0.1919 - val_mse: 1.3405 - learning_rate: 1.0000e-04\n",
      "Epoch 94/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 8ms/step - loss: 0.1033 - mae: 0.1934 - mse: 1.3503 - val_loss: 0.1029 - val_mae: 0.1925 - val_mse: 1.3434 - learning_rate: 1.0000e-04\n",
      "Epoch 95/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - loss: 0.1006 - mae: 0.1905 - mse: 1.2989 - val_loss: 0.1021 - val_mae: 0.1913 - val_mse: 1.3377 - learning_rate: 1.0000e-04\n",
      "Epoch 96/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - loss: 0.1013 - mae: 0.1911 - mse: 1.3117 - val_loss: 0.1021 - val_mae: 0.1913 - val_mse: 1.3374 - learning_rate: 1.0000e-04\n",
      "Epoch 97/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - loss: 0.1037 - mae: 0.1934 - mse: 1.3547 - val_loss: 0.1020 - val_mae: 0.1915 - val_mse: 1.3306 - learning_rate: 1.0000e-04\n",
      "Epoch 98/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - loss: 0.1044 - mae: 0.1939 - mse: 1.3689 - val_loss: 0.1016 - val_mae: 0.1914 - val_mse: 1.3272 - learning_rate: 1.0000e-04\n",
      "Epoch 99/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - loss: 0.1047 - mae: 0.1940 - mse: 1.3756 - val_loss: 0.1013 - val_mae: 0.1905 - val_mse: 1.3286 - learning_rate: 1.0000e-04\n",
      "Epoch 100/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - loss: 0.1019 - mae: 0.1918 - mse: 1.3237 - val_loss: 0.1011 - val_mae: 0.1907 - val_mse: 1.3207 - learning_rate: 1.0000e-04\n",
      "Epoch 101/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - loss: 0.1062 - mae: 0.1957 - mse: 1.4026 - val_loss: 0.1012 - val_mae: 0.1901 - val_mse: 1.3235 - learning_rate: 1.0000e-04\n",
      "Epoch 102/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - loss: 0.1003 - mae: 0.1898 - mse: 1.3031 - val_loss: 0.1008 - val_mae: 0.1897 - val_mse: 1.3189 - learning_rate: 1.0000e-04\n",
      "Epoch 103/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - loss: 0.1001 - mae: 0.1896 - mse: 1.3051 - val_loss: 0.1006 - val_mae: 0.1901 - val_mse: 1.3147 - learning_rate: 1.0000e-04\n",
      "Epoch 104/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - loss: 0.0995 - mae: 0.1886 - mse: 1.2915 - val_loss: 0.1003 - val_mae: 0.1893 - val_mse: 1.3097 - learning_rate: 1.0000e-04\n",
      "Epoch 105/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - loss: 0.1040 - mae: 0.1928 - mse: 1.3652 - val_loss: 0.1004 - val_mae: 0.1894 - val_mse: 1.3108 - learning_rate: 1.0000e-04\n",
      "Epoch 106/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - loss: 0.1030 - mae: 0.1924 - mse: 1.3459 - val_loss: 0.0998 - val_mae: 0.1883 - val_mse: 1.3075 - learning_rate: 1.0000e-04\n",
      "Epoch 107/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - loss: 0.0967 - mae: 0.1853 - mse: 1.2643 - val_loss: 0.1003 - val_mae: 0.1893 - val_mse: 1.3099 - learning_rate: 1.0000e-04\n",
      "Epoch 108/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - loss: 0.0991 - mae: 0.1879 - mse: 1.2929 - val_loss: 0.0996 - val_mae: 0.1884 - val_mse: 1.3028 - learning_rate: 1.0000e-04\n",
      "Epoch 109/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - loss: 0.1037 - mae: 0.1930 - mse: 1.3577 - val_loss: 0.0996 - val_mae: 0.1884 - val_mse: 1.3017 - learning_rate: 1.0000e-04\n",
      "Epoch 110/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - loss: 0.0989 - mae: 0.1877 - mse: 1.2903 - val_loss: 0.0991 - val_mae: 0.1874 - val_mse: 1.2982 - learning_rate: 1.0000e-04\n",
      "Epoch 111/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - loss: 0.1010 - mae: 0.1894 - mse: 1.3271 - val_loss: 0.0994 - val_mae: 0.1882 - val_mse: 1.3003 - learning_rate: 1.0000e-04\n",
      "Epoch 112/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - loss: 0.1012 - mae: 0.1906 - mse: 1.3162 - val_loss: 0.0989 - val_mae: 0.1870 - val_mse: 1.2936 - learning_rate: 1.0000e-04\n",
      "Epoch 113/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - loss: 0.0982 - mae: 0.1870 - mse: 1.2738 - val_loss: 0.0989 - val_mae: 0.1877 - val_mse: 1.2896 - learning_rate: 1.0000e-04\n",
      "Epoch 114/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - loss: 0.1008 - mae: 0.1895 - mse: 1.3273 - val_loss: 0.0986 - val_mae: 0.1874 - val_mse: 1.2876 - learning_rate: 1.0000e-04\n",
      "Epoch 115/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - loss: 0.0984 - mae: 0.1873 - mse: 1.2745 - val_loss: 0.0983 - val_mae: 0.1868 - val_mse: 1.2846 - learning_rate: 1.0000e-04\n",
      "Epoch 116/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - loss: 0.0991 - mae: 0.1880 - mse: 1.2988 - val_loss: 0.0985 - val_mae: 0.1868 - val_mse: 1.2872 - learning_rate: 1.0000e-04\n",
      "Epoch 117/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - loss: 0.0969 - mae: 0.1855 - mse: 1.2649 - val_loss: 0.0985 - val_mae: 0.1874 - val_mse: 1.2822 - learning_rate: 1.0000e-04\n",
      "Epoch 118/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - loss: 0.0987 - mae: 0.1873 - mse: 1.2805 - val_loss: 0.0979 - val_mae: 0.1864 - val_mse: 1.2784 - learning_rate: 1.0000e-04\n",
      "Epoch 119/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - loss: 0.0975 - mae: 0.1861 - mse: 1.2687 - val_loss: 0.0978 - val_mae: 0.1861 - val_mse: 1.2770 - learning_rate: 1.0000e-04\n",
      "Epoch 120/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - loss: 0.1018 - mae: 0.1906 - mse: 1.3370 - val_loss: 0.0977 - val_mae: 0.1862 - val_mse: 1.2768 - learning_rate: 1.0000e-04\n",
      "Epoch 121/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - loss: 0.0979 - mae: 0.1858 - mse: 1.2901 - val_loss: 0.0977 - val_mae: 0.1860 - val_mse: 1.2708 - learning_rate: 1.0000e-04\n",
      "Epoch 122/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - loss: 0.0985 - mae: 0.1869 - mse: 1.2849 - val_loss: 0.0975 - val_mae: 0.1860 - val_mse: 1.2724 - learning_rate: 1.0000e-04\n",
      "Epoch 123/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 8ms/step - loss: 0.1010 - mae: 0.1897 - mse: 1.3174 - val_loss: 0.0974 - val_mae: 0.1857 - val_mse: 1.2701 - learning_rate: 1.0000e-04\n",
      "Epoch 124/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - loss: 0.0966 - mae: 0.1846 - mse: 1.2528 - val_loss: 0.0973 - val_mae: 0.1857 - val_mse: 1.2687 - learning_rate: 1.0000e-04\n",
      "Epoch 125/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - loss: 0.0977 - mae: 0.1859 - mse: 1.2785 - val_loss: 0.0971 - val_mae: 0.1852 - val_mse: 1.2668 - learning_rate: 1.0000e-04\n",
      "Epoch 126/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - loss: 0.0996 - mae: 0.1880 - mse: 1.3107 - val_loss: 0.0966 - val_mae: 0.1842 - val_mse: 1.2630 - learning_rate: 1.0000e-04\n",
      "Epoch 127/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - loss: 0.0971 - mae: 0.1852 - mse: 1.2601 - val_loss: 0.0968 - val_mae: 0.1854 - val_mse: 1.2536 - learning_rate: 1.0000e-04\n",
      "Epoch 128/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - loss: 0.0990 - mae: 0.1879 - mse: 1.2926 - val_loss: 0.0963 - val_mae: 0.1847 - val_mse: 1.2537 - learning_rate: 1.0000e-04\n",
      "Epoch 129/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - loss: 0.0975 - mae: 0.1860 - mse: 1.2785 - val_loss: 0.0961 - val_mae: 0.1842 - val_mse: 1.2530 - learning_rate: 1.0000e-04\n",
      "Epoch 130/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - loss: 0.0981 - mae: 0.1862 - mse: 1.2770 - val_loss: 0.0963 - val_mae: 0.1841 - val_mse: 1.2554 - learning_rate: 1.0000e-04\n",
      "Epoch 131/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - loss: 0.0981 - mae: 0.1862 - mse: 1.2787 - val_loss: 0.0959 - val_mae: 0.1840 - val_mse: 1.2509 - learning_rate: 1.0000e-04\n",
      "Epoch 132/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - loss: 0.0953 - mae: 0.1835 - mse: 1.2349 - val_loss: 0.0958 - val_mae: 0.1836 - val_mse: 1.2510 - learning_rate: 1.0000e-04\n",
      "Epoch 133/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - loss: 0.0983 - mae: 0.1868 - mse: 1.2820 - val_loss: 0.0957 - val_mae: 0.1839 - val_mse: 1.2457 - learning_rate: 1.0000e-04\n",
      "Epoch 134/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - loss: 0.0941 - mae: 0.1824 - mse: 1.2112 - val_loss: 0.0956 - val_mae: 0.1837 - val_mse: 1.2417 - learning_rate: 1.0000e-04\n",
      "Epoch 135/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - loss: 0.0948 - mae: 0.1829 - mse: 1.2311 - val_loss: 0.0958 - val_mae: 0.1840 - val_mse: 1.2415 - learning_rate: 1.0000e-04\n",
      "Epoch 136/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - loss: 0.0939 - mae: 0.1817 - mse: 1.2125 - val_loss: 0.0953 - val_mae: 0.1833 - val_mse: 1.2380 - learning_rate: 1.0000e-04\n",
      "Epoch 137/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - loss: 0.0979 - mae: 0.1866 - mse: 1.2657 - val_loss: 0.0956 - val_mae: 0.1837 - val_mse: 1.2388 - learning_rate: 1.0000e-04\n",
      "Epoch 138/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 9ms/step - loss: 0.0940 - mae: 0.1820 - mse: 1.2092 - val_loss: 0.0945 - val_mae: 0.1820 - val_mse: 1.2303 - learning_rate: 1.0000e-04\n",
      "Epoch 139/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - loss: 0.0969 - mae: 0.1852 - mse: 1.2620 - val_loss: 0.0951 - val_mae: 0.1827 - val_mse: 1.2384 - learning_rate: 1.0000e-04\n",
      "Epoch 140/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - loss: 0.0946 - mae: 0.1825 - mse: 1.2393 - val_loss: 0.0949 - val_mae: 0.1825 - val_mse: 1.2316 - learning_rate: 1.0000e-04\n",
      "Epoch 141/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - loss: 0.0978 - mae: 0.1861 - mse: 1.2771 - val_loss: 0.0944 - val_mae: 0.1818 - val_mse: 1.2303 - learning_rate: 1.0000e-04\n",
      "Epoch 142/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - loss: 0.0933 - mae: 0.1814 - mse: 1.2170 - val_loss: 0.0942 - val_mae: 0.1818 - val_mse: 1.2232 - learning_rate: 1.0000e-04\n",
      "Epoch 143/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - loss: 0.0966 - mae: 0.1840 - mse: 1.2661 - val_loss: 0.0941 - val_mae: 0.1817 - val_mse: 1.2230 - learning_rate: 1.0000e-04\n",
      "Epoch 144/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - loss: 0.0980 - mae: 0.1861 - mse: 1.2850 - val_loss: 0.0940 - val_mae: 0.1814 - val_mse: 1.2253 - learning_rate: 1.0000e-04\n",
      "Epoch 145/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 8ms/step - loss: 0.0928 - mae: 0.1807 - mse: 1.2021 - val_loss: 0.0942 - val_mae: 0.1815 - val_mse: 1.2259 - learning_rate: 1.0000e-04\n",
      "Epoch 146/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - loss: 0.0946 - mae: 0.1822 - mse: 1.2240 - val_loss: 0.0937 - val_mae: 0.1816 - val_mse: 1.2173 - learning_rate: 1.0000e-04\n",
      "Epoch 147/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - loss: 0.0954 - mae: 0.1835 - mse: 1.2481 - val_loss: 0.0940 - val_mae: 0.1816 - val_mse: 1.2219 - learning_rate: 1.0000e-04\n",
      "Epoch 148/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - loss: 0.0937 - mae: 0.1813 - mse: 1.2035 - val_loss: 0.0934 - val_mae: 0.1803 - val_mse: 1.2189 - learning_rate: 1.0000e-04\n",
      "Epoch 149/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - loss: 0.0910 - mae: 0.1781 - mse: 1.1876 - val_loss: 0.0936 - val_mae: 0.1806 - val_mse: 1.2200 - learning_rate: 1.0000e-04\n",
      "Epoch 150/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - loss: 0.0954 - mae: 0.1833 - mse: 1.2271 - val_loss: 0.0933 - val_mae: 0.1805 - val_mse: 1.2164 - learning_rate: 1.0000e-04\n",
      "Epoch 151/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - loss: 0.0947 - mae: 0.1818 - mse: 1.2413 - val_loss: 0.0934 - val_mae: 0.1806 - val_mse: 1.2160 - learning_rate: 1.0000e-04\n",
      "Epoch 152/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 8ms/step - loss: 0.0936 - mae: 0.1813 - mse: 1.2100 - val_loss: 0.0934 - val_mae: 0.1805 - val_mse: 1.2164 - learning_rate: 1.0000e-04\n",
      "Epoch 153/1000\n",
      "\u001b[1m1773/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0930 - mae: 0.1804 - mse: 1.2047\n",
      "Epoch 153: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - loss: 0.0930 - mae: 0.1804 - mse: 1.2047 - val_loss: 0.0932 - val_mae: 0.1808 - val_mse: 1.2083 - learning_rate: 1.0000e-04\n",
      "Epoch 154/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - loss: 0.0945 - mae: 0.1816 - mse: 1.2338 - val_loss: 0.0924 - val_mae: 0.1792 - val_mse: 1.2057 - learning_rate: 1.0000e-05\n",
      "Epoch 155/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - loss: 0.0946 - mae: 0.1815 - mse: 1.2453 - val_loss: 0.0921 - val_mae: 0.1788 - val_mse: 1.2032 - learning_rate: 1.0000e-05\n",
      "Epoch 156/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - loss: 0.0945 - mae: 0.1816 - mse: 1.2293 - val_loss: 0.0920 - val_mae: 0.1787 - val_mse: 1.2021 - learning_rate: 1.0000e-05\n",
      "Epoch 157/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - loss: 0.0937 - mae: 0.1804 - mse: 1.2226 - val_loss: 0.0920 - val_mae: 0.1785 - val_mse: 1.2018 - learning_rate: 1.0000e-05\n",
      "Epoch 158/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - loss: 0.0882 - mae: 0.1744 - mse: 1.1436 - val_loss: 0.0919 - val_mae: 0.1786 - val_mse: 1.2005 - learning_rate: 1.0000e-05\n",
      "Epoch 159/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - loss: 0.0916 - mae: 0.1780 - mse: 1.1963 - val_loss: 0.0919 - val_mae: 0.1785 - val_mse: 1.2003 - learning_rate: 1.0000e-05\n",
      "Epoch 160/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - loss: 0.0937 - mae: 0.1805 - mse: 1.2337 - val_loss: 0.0918 - val_mae: 0.1785 - val_mse: 1.1997 - learning_rate: 1.0000e-05\n",
      "Epoch 161/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - loss: 0.0915 - mae: 0.1783 - mse: 1.1982 - val_loss: 0.0918 - val_mae: 0.1784 - val_mse: 1.1997 - learning_rate: 1.0000e-05\n",
      "Epoch 162/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - loss: 0.0907 - mae: 0.1773 - mse: 1.1795 - val_loss: 0.0918 - val_mae: 0.1783 - val_mse: 1.1989 - learning_rate: 1.0000e-05\n",
      "Epoch 163/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - loss: 0.0955 - mae: 0.1823 - mse: 1.2578 - val_loss: 0.0917 - val_mae: 0.1782 - val_mse: 1.1992 - learning_rate: 1.0000e-05\n",
      "Epoch 164/1000\n",
      "\u001b[1m1772/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0930 - mae: 0.1797 - mse: 1.2143\n",
      "Epoch 164: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - loss: 0.0930 - mae: 0.1797 - mse: 1.2143 - val_loss: 0.0917 - val_mae: 0.1782 - val_mse: 1.1990 - learning_rate: 1.0000e-05\n",
      "Epoch 165/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - loss: 0.0913 - mae: 0.1776 - mse: 1.1944 - val_loss: 0.0917 - val_mae: 0.1782 - val_mse: 1.1988 - learning_rate: 1.0000e-06\n",
      "Epoch 166/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - loss: 0.0884 - mae: 0.1746 - mse: 1.1588 - val_loss: 0.0917 - val_mae: 0.1782 - val_mse: 1.1986 - learning_rate: 1.0000e-06\n",
      "Epoch 167/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - loss: 0.0918 - mae: 0.1781 - mse: 1.2088 - val_loss: 0.0917 - val_mae: 0.1782 - val_mse: 1.1985 - learning_rate: 1.0000e-06\n",
      "Epoch 168/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - loss: 0.0938 - mae: 0.1806 - mse: 1.2248 - val_loss: 0.0917 - val_mae: 0.1782 - val_mse: 1.1984 - learning_rate: 1.0000e-06\n",
      "Epoch 169/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - loss: 0.0924 - mae: 0.1790 - mse: 1.2113 - val_loss: 0.0917 - val_mae: 0.1782 - val_mse: 1.1983 - learning_rate: 1.0000e-06\n",
      "Epoch 170/1000\n",
      "\u001b[1m1774/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0900 - mae: 0.1765 - mse: 1.1626\n",
      "Epoch 170: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - loss: 0.0900 - mae: 0.1765 - mse: 1.1627 - val_loss: 0.0917 - val_mae: 0.1782 - val_mse: 1.1982 - learning_rate: 1.0000e-06\n",
      "Epoch 171/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - loss: 0.0915 - mae: 0.1780 - mse: 1.1906 - val_loss: 0.0917 - val_mae: 0.1782 - val_mse: 1.1982 - learning_rate: 1.0000e-07\n",
      "Epoch 172/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - loss: 0.0914 - mae: 0.1778 - mse: 1.1946 - val_loss: 0.0917 - val_mae: 0.1782 - val_mse: 1.1982 - learning_rate: 1.0000e-07\n",
      "Epoch 173/1000\n",
      "\u001b[1m1772/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0930 - mae: 0.1800 - mse: 1.2097\n",
      "Epoch 173: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - loss: 0.0930 - mae: 0.1800 - mse: 1.2097 - val_loss: 0.0917 - val_mae: 0.1782 - val_mse: 1.1982 - learning_rate: 1.0000e-07\n",
      "Epoch 174/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - loss: 0.0916 - mae: 0.1785 - mse: 1.1947 - val_loss: 0.0917 - val_mae: 0.1782 - val_mse: 1.1982 - learning_rate: 1.0000e-08\n",
      "Epoch 175/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - loss: 0.0955 - mae: 0.1823 - mse: 1.2626 - val_loss: 0.0917 - val_mae: 0.1782 - val_mse: 1.1982 - learning_rate: 1.0000e-08\n",
      "Epoch 176/1000\n",
      "\u001b[1m1772/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0891 - mae: 0.1757 - mse: 1.1589\n",
      "Epoch 176: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-09.\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - loss: 0.0891 - mae: 0.1757 - mse: 1.1590 - val_loss: 0.0917 - val_mae: 0.1782 - val_mse: 1.1982 - learning_rate: 1.0000e-08\n",
      "Epoch 177/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - loss: 0.0941 - mae: 0.1805 - mse: 1.2352 - val_loss: 0.0917 - val_mae: 0.1782 - val_mse: 1.1982 - learning_rate: 1.0000e-09\n",
      "Epoch 178/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - loss: 0.0944 - mae: 0.1814 - mse: 1.2489 - val_loss: 0.0917 - val_mae: 0.1782 - val_mse: 1.1982 - learning_rate: 1.0000e-09\n",
      "Epoch 179/1000\n",
      "\u001b[1m1768/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0925 - mae: 0.1792 - mse: 1.2178\n",
      "Epoch 179: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-10.\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - loss: 0.0925 - mae: 0.1792 - mse: 1.2177 - val_loss: 0.0917 - val_mae: 0.1782 - val_mse: 1.1982 - learning_rate: 1.0000e-09\n",
      "Epoch 180/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - loss: 0.0929 - mae: 0.1796 - mse: 1.2165 - val_loss: 0.0917 - val_mae: 0.1782 - val_mse: 1.1982 - learning_rate: 1.0000e-10\n",
      "Epoch 181/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - loss: 0.0912 - mae: 0.1774 - mse: 1.2048 - val_loss: 0.0917 - val_mae: 0.1782 - val_mse: 1.1982 - learning_rate: 1.0000e-10\n",
      "Epoch 181: early stopping\n"
     ]
    }
   ],
   "source": [
    "huber_loss = Huber(delta=1.0)\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(6, 7), return_sequences=True))\n",
    "model.add(LSTM(64, return_sequences=True))\n",
    "model.add(LSTM(32, return_sequences=True))\n",
    "model.add(TimeDistributed(Dense(7, activation='linear')))\n",
    "model.summary()\n",
    "model.compile(optimizer='adam', loss=huber_loss, metrics=['mse','mae'])\n",
    "checkpoint = ModelCheckpoint(model_name + '_best.keras', monitor='val_loss', save_best_only=True)\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, verbose=1)\n",
    "hist = model.fit(japonica_training_features_X_chunks_crop, japonica_training_features_y_chunks_crop, epochs = 1000, batch_size = 6, validation_data=(japonica_validation_features_X_chunks_crop, japonica_validation_features_y_chunks_crop), callbacks=[checkpoint, early_stop, reduce_lr])\n",
    "model.save(model_name+'.keras')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "doRegressor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
