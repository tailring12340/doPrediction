{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "라이브러리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.utils import *\n",
    "from keras.layers import LSTM, Dense, TimeDistributed\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from sklearn.preprocessing import *\n",
    "from keras.losses import Huber\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "model_name = 'model/Aqua_all_standard'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "japonica_training = pd.DataFrame()\n",
    "japonica_validation = pd.DataFrame()\n",
    "\n",
    "for i in range(5):\n",
    "    tank = i + 1\n",
    "    japonica_training_food_supply_tb = pd.read_csv(\"E:/kimwoojae/Research/DO Regressor/dataset/japonica_training_food_supply_tb.csv\")\n",
    "    japonica_training_sensor_val_tb = pd.read_csv(\"E:/kimwoojae/Research/DO Regressor/dataset/japonica_training_sensor_val_tb.csv\")\n",
    "    japonica_validation_food_supply_tb = pd.read_csv(\"E:/kimwoojae/Research/DO Regressor/dataset/japonica_validation_food_supply_tb.csv\")\n",
    "    japonica_validation_sensor_val_tb = pd.read_csv(\"E:/kimwoojae/Research/DO Regressor/dataset/japonica_validation_sensor_val_tb.csv\")\n",
    "    japonica_training_food_supply_tb = japonica_training_food_supply_tb[japonica_training_food_supply_tb['tank_id']==tank]\n",
    "    japonica_validation_food_supply_tb = japonica_validation_food_supply_tb[japonica_validation_food_supply_tb['tank_id']==tank]\n",
    "    japonica_training_food_supply_tb = japonica_training_food_supply_tb[japonica_training_food_supply_tb['feed_quantity'].notnull()]\n",
    "    japonica_validation_food_supply_tb = japonica_validation_food_supply_tb[japonica_validation_food_supply_tb['feed_quantity'].notnull()]\n",
    "    japonica_training_food_supply_tb['feed_dt'] = pd.to_datetime(japonica_training_food_supply_tb['feed_dt'], format='%Y%m%d%H%M', errors='raise')\n",
    "    japonica_training_food_supply_tb[\"feed_dt\"] = japonica_training_food_supply_tb[\"feed_dt\"].apply(str)\n",
    "    japonica_training_food_supply_tb[\"feed_dt\"] = japonica_training_food_supply_tb[\"feed_dt\"].str.slice(start=0, stop=16)\n",
    "    japonica_validation_food_supply_tb['feed_dt'] = pd.to_datetime(japonica_validation_food_supply_tb['feed_dt'], format='%Y%m%d%H%M', errors='raise')\n",
    "    japonica_validation_food_supply_tb[\"feed_dt\"] = japonica_validation_food_supply_tb[\"feed_dt\"].apply(str)\n",
    "    japonica_validation_food_supply_tb[\"feed_dt\"] = japonica_validation_food_supply_tb[\"feed_dt\"].str.slice(start=0, stop=16)\n",
    "    japonica_training_sensor_val_tb = japonica_training_sensor_val_tb[japonica_training_sensor_val_tb['tank_id']==tank]\n",
    "    japonica_validation_sensor_val_tb = japonica_validation_sensor_val_tb[japonica_validation_sensor_val_tb['tank_id']==tank]\n",
    "    japonica_training_sensor_val_tb[\"mea_dt\"] = japonica_training_sensor_val_tb[\"mea_dt\"].apply(str)\n",
    "    japonica_training_sensor_val_tb[\"mea_dt\"] = japonica_training_sensor_val_tb[\"mea_dt\"].str.slice(start=0, stop=16)\n",
    "    japonica_training_sensor_val_tb['mea_dt'] = pd.to_datetime(japonica_training_sensor_val_tb['mea_dt'], format='%Y-%m-%d %H:%M', errors='raise')\n",
    "    japonica_validation_sensor_val_tb[\"mea_dt\"] = japonica_validation_sensor_val_tb[\"mea_dt\"].apply(str)\n",
    "    japonica_validation_sensor_val_tb[\"mea_dt\"] = japonica_validation_sensor_val_tb[\"mea_dt\"].str.slice(start=0, stop=16)\n",
    "    japonica_validation_sensor_val_tb['mea_dt'] = pd.to_datetime(japonica_validation_sensor_val_tb['mea_dt'], format='%Y-%m-%d %H:%M', errors='raise')\n",
    "    japonica_training_sensor_val_tb['date'] = pd.to_datetime(japonica_training_sensor_val_tb['mea_dt']).dt.date\n",
    "    japonica_training_food_supply_tb['date'] = pd.to_datetime(japonica_training_food_supply_tb['feed_dt']).dt.date\n",
    "    common_dates = japonica_training_sensor_val_tb['date'].isin(japonica_training_food_supply_tb['date'])\n",
    "    japonica_training_sensor_val_tb = japonica_training_sensor_val_tb[common_dates]\n",
    "    japonica_training_sensor_val_tb = japonica_training_sensor_val_tb.drop('date', axis=1)\n",
    "    japonica_validation_sensor_val_tb['date'] = pd.to_datetime(japonica_validation_sensor_val_tb['mea_dt']).dt.date\n",
    "    japonica_validation_food_supply_tb['date'] = pd.to_datetime(japonica_validation_food_supply_tb['feed_dt']).dt.date\n",
    "    common_dates = japonica_validation_sensor_val_tb['date'].isin(japonica_validation_food_supply_tb['date'])\n",
    "    japonica_validation_sensor_val_tb = japonica_validation_sensor_val_tb[common_dates]\n",
    "    japonica_validation_sensor_val_tb = japonica_validation_sensor_val_tb.drop('date', axis=1)\n",
    "    japonica_training_sensor_val_tb.set_index('mea_dt', inplace=True)\n",
    "    japonica_training_sensor_val_tb = japonica_training_sensor_val_tb.resample('30min').mean()\n",
    "    japonica_training_sensor_val_tb = japonica_training_sensor_val_tb.reset_index()\n",
    "    japonica_training_sensor_val_tb = japonica_training_sensor_val_tb.dropna()\n",
    "    japonica_validation_sensor_val_tb.set_index('mea_dt', inplace=True)\n",
    "    japonica_validation_sensor_val_tb = japonica_validation_sensor_val_tb.resample('30min').mean()\n",
    "    japonica_validation_sensor_val_tb = japonica_validation_sensor_val_tb.reset_index()\n",
    "    japonica_validation_sensor_val_tb = japonica_validation_sensor_val_tb.dropna()\n",
    "    training_counts = japonica_training_sensor_val_tb.groupby(japonica_training_sensor_val_tb['mea_dt'].dt.date).size()\n",
    "    validation_counts = japonica_validation_sensor_val_tb.groupby(japonica_validation_sensor_val_tb['mea_dt'].dt.date).size()\n",
    "    to_delete = training_counts[training_counts != 48].index\n",
    "    japonica_training_sensor_val_tb = japonica_training_sensor_val_tb[~japonica_training_sensor_val_tb['mea_dt'].dt.date.isin(to_delete)]\n",
    "    to_delete = validation_counts[validation_counts != 48].index\n",
    "    japonica_validation_sensor_val_tb = japonica_validation_sensor_val_tb[~japonica_validation_sensor_val_tb['mea_dt'].dt.date.isin(to_delete)]\n",
    "    japonica_training_sensor_val_tb[\"mea_dt\"] = japonica_training_sensor_val_tb[\"mea_dt\"].dt.strftime('%Y-%m-%d %H:%M')\n",
    "    japonica_training_sensor_val_tb[\"mea_dt\"] = japonica_training_sensor_val_tb[\"mea_dt\"].str.slice(start=0, stop=16)\n",
    "    japonica_validation_sensor_val_tb[\"mea_dt\"] = japonica_validation_sensor_val_tb[\"mea_dt\"].dt.strftime('%Y-%m-%d %H:%M')\n",
    "    japonica_validation_sensor_val_tb[\"mea_dt\"] = japonica_validation_sensor_val_tb[\"mea_dt\"].str.slice(start=0, stop=16)\n",
    "    japonica_training_features = pd.merge(left = japonica_training_sensor_val_tb, right = japonica_training_food_supply_tb, how = \"left\", left_on = [\"farm_id\",\"tank_id\", \"mea_dt\"], right_on = [\"farm_id\",\"tank_id\", \"feed_dt\"])\n",
    "    japonica_validation_features = pd.merge(left = japonica_validation_sensor_val_tb, right = japonica_validation_food_supply_tb, how = \"left\", left_on = [\"farm_id\",\"tank_id\", \"mea_dt\"], right_on = [\"farm_id\",\"tank_id\", \"feed_dt\"])\n",
    "    japonica_training_features['mea_dt'] = pd.to_datetime(japonica_training_features['mea_dt'], format='%Y-%m-%d %H:%M', errors='raise')\n",
    "    japonica_validation_features['mea_dt'] = pd.to_datetime(japonica_validation_features['mea_dt'], format='%Y-%m-%d %H:%M', errors='raise')\n",
    "    feature_origin = ['tank_id','mea_dt', 'do_mg','do_temp', 'ph', 'orp', 'co2_mg', 'air_oxy', 'light_ma', 'feed_quantity', 'water_quantity']\n",
    "    japonica_training_features = japonica_training_features[feature_origin]\n",
    "    japonica_validation_features = japonica_validation_features[feature_origin]\n",
    "    japonica_training_features = japonica_training_features.fillna(0)\n",
    "    japonica_validation_features = japonica_validation_features.fillna(0)\n",
    "    japonica_training_features.set_index('mea_dt', inplace=True)\n",
    "    japonica_validation_features.set_index('mea_dt', inplace=True)\n",
    "    japonica_training_data = japonica_training_features.sort_index()\n",
    "    japonica_validation_data = japonica_validation_features.sort_index()\n",
    "    japonica_training_data = japonica_training_data.reset_index()\n",
    "    japonica_validation_data = japonica_validation_data.reset_index()\n",
    "    japonica_training_data = japonica_training_data[['do_mg','do_temp', 'ph', 'orp', 'co2_mg', 'feed_quantity', 'water_quantity']]\n",
    "    japonica_validation_data = japonica_validation_data[['do_mg','do_temp', 'ph', 'orp', 'co2_mg', 'feed_quantity', 'water_quantity']]\n",
    "    japonica_training = pd.concat([japonica_training, japonica_training_data])\n",
    "    japonica_validation = pd.concat([japonica_validation, japonica_validation_data])\n",
    "    japonica_training.reset_index(drop=True, inplace=True)\n",
    "    japonica_validation.reset_index(drop=True, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "train_standardized = scaler.fit_transform(japonica_training)\n",
    "japonica_training_standard = pd.DataFrame({'Datetime': japonica_training.index, 'do_mg': train_standardized[:, 0],'do_temp': train_standardized[:, 1],'ph': train_standardized[:, 2],'orp': train_standardized[:, 3],'co2_mg': train_standardized[:, 4], 'feed_quantity': train_standardized[:, 5],'water_quantity': train_standardized[:, 6]})\n",
    "japonica_training_standard.set_index('Datetime', inplace=True)\n",
    "test_standardized = scaler.transform(japonica_validation)\n",
    "japonica_validation_standard = pd.DataFrame({'Datetime': japonica_validation.index, 'do_mg': test_standardized[:, 0],'do_temp': test_standardized[:, 1],'ph': test_standardized[:, 2],'orp': test_standardized[:, 3],'co2_mg': test_standardized[:, 4], 'feed_quantity': test_standardized[:, 5],'water_quantity': test_standardized[:, 6]})\n",
    "japonica_validation_standard.set_index('Datetime', inplace=True)\n",
    "japonica_training_features_X = japonica_training_standard.copy()\n",
    "japonica_training_features_y = japonica_training_standard.copy()\n",
    "japonica_validation_features_X = japonica_validation_standard.copy()\n",
    "japonica_validation_features_y = japonica_validation_standard.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10645, 6, 7)\n",
      "(10645, 6, 7)\n",
      "(10645, 6, 7)\n",
      "(10645, 6, 7)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "japonica_training_features_X_chunks = []\n",
    "japonica_training_features_y_chunks = []\n",
    "japonica_validation_features_X_chunks = []\n",
    "japonica_validation_features_y_chunks = []\n",
    "for i in range(0, len(japonica_training_features_X) - 5):\n",
    "    japonica_training_features_X_chunks.append(np.array(japonica_training_features_X.iloc[i:i+6].values, dtype=np.float64))\n",
    "japonica_training_features_X_chunks = np.array(japonica_training_features_X_chunks, dtype=np.float64)\n",
    "for i in range(0, len(japonica_training_features_y) - 5):\n",
    "    japonica_training_features_y_chunks.append(np.array(japonica_training_features_y.iloc[i:i+6].values, dtype=np.float64))\n",
    "japonica_training_features_y_chunks = np.array(japonica_training_features_y_chunks, dtype=np.float64)\n",
    "for i in range(0, len(japonica_validation_features_X) - 5):\n",
    "    japonica_validation_features_X_chunks.append(np.array(japonica_validation_features_X.iloc[i:i+6].values, dtype=np.float64))\n",
    "japonica_validation_features_X_chunks = np.array(japonica_validation_features_X_chunks, dtype=np.float64)\n",
    "for i in range(0, len(japonica_validation_features_y) - 5):\n",
    "    japonica_validation_features_y_chunks.append(np.array(japonica_validation_features_y.iloc[i:i+6].values, dtype=np.float64))\n",
    "japonica_validation_features_y_chunks = np.array(japonica_validation_features_y_chunks, dtype=np.float64)\n",
    "japonica_training_features_X_chunks_crop = japonica_training_features_X_chunks[:-6]\n",
    "japonica_training_features_y_chunks_crop = japonica_training_features_y_chunks[6:]\n",
    "japonica_validation_features_X_chunks_crop = japonica_validation_features_X_chunks[:-6]\n",
    "japonica_validation_features_y_chunks_crop = japonica_validation_features_y_chunks[6:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rladn\\anaconda3\\envs\\do\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">69,632</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │        <span style=\"color: #00af00; text-decoration-color: #00af00\">49,408</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │        <span style=\"color: #00af00; text-decoration-color: #00af00\">12,416</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)           │           <span style=\"color: #00af00; text-decoration-color: #00af00\">231</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │        \u001b[38;5;34m69,632\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │        \u001b[38;5;34m49,408\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │        \u001b[38;5;34m12,416\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m7\u001b[0m)           │           \u001b[38;5;34m231\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">131,687</span> (514.40 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m131,687\u001b[0m (514.40 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">131,687</span> (514.40 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m131,687\u001b[0m (514.40 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 8ms/step - loss: 0.1392 - mae: 0.3186 - mse: 0.4927 - val_loss: 0.0920 - val_mae: 0.2237 - val_mse: 0.3866 - learning_rate: 0.0010\n",
      "Epoch 2/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - loss: 0.0885 - mae: 0.2146 - mse: 0.3811 - val_loss: 0.0853 - val_mae: 0.2060 - val_mse: 0.3726 - learning_rate: 0.0010\n",
      "Epoch 3/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - loss: 0.0837 - mae: 0.2027 - mse: 0.3652 - val_loss: 0.0827 - val_mae: 0.2005 - val_mse: 0.3653 - learning_rate: 0.0010\n",
      "Epoch 4/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - loss: 0.0835 - mae: 0.1999 - mse: 0.3698 - val_loss: 0.0807 - val_mae: 0.1939 - val_mse: 0.3607 - learning_rate: 0.0010\n",
      "Epoch 5/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - loss: 0.0799 - mae: 0.1931 - mse: 0.3579 - val_loss: 0.0780 - val_mae: 0.1875 - val_mse: 0.3539 - learning_rate: 0.0010\n",
      "Epoch 6/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - loss: 0.0785 - mae: 0.1891 - mse: 0.3546 - val_loss: 0.0770 - val_mae: 0.1863 - val_mse: 0.3513 - learning_rate: 0.0010\n",
      "Epoch 7/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - loss: 0.0774 - mae: 0.1871 - mse: 0.3522 - val_loss: 0.0760 - val_mae: 0.1849 - val_mse: 0.3472 - learning_rate: 0.0010\n",
      "Epoch 8/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - loss: 0.0753 - mae: 0.1828 - mse: 0.3459 - val_loss: 0.0743 - val_mae: 0.1796 - val_mse: 0.3435 - learning_rate: 0.0010\n",
      "Epoch 9/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 8ms/step - loss: 0.0735 - mae: 0.1797 - mse: 0.3361 - val_loss: 0.0733 - val_mae: 0.1774 - val_mse: 0.3406 - learning_rate: 0.0010\n",
      "Epoch 10/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - loss: 0.0748 - mae: 0.1812 - mse: 0.3452 - val_loss: 0.0734 - val_mae: 0.1769 - val_mse: 0.3411 - learning_rate: 0.0010\n",
      "Epoch 11/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - loss: 0.0736 - mae: 0.1785 - mse: 0.3415 - val_loss: 0.0721 - val_mae: 0.1769 - val_mse: 0.3361 - learning_rate: 0.0010\n",
      "Epoch 12/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - loss: 0.0729 - mae: 0.1771 - mse: 0.3413 - val_loss: 0.0709 - val_mae: 0.1757 - val_mse: 0.3308 - learning_rate: 0.0010\n",
      "Epoch 13/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - loss: 0.0719 - mae: 0.1758 - mse: 0.3348 - val_loss: 0.0712 - val_mae: 0.1766 - val_mse: 0.3299 - learning_rate: 0.0010\n",
      "Epoch 14/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - loss: 0.0706 - mae: 0.1733 - mse: 0.3302 - val_loss: 0.0696 - val_mae: 0.1709 - val_mse: 0.3264 - learning_rate: 0.0010\n",
      "Epoch 15/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - loss: 0.0696 - mae: 0.1709 - mse: 0.3269 - val_loss: 0.0692 - val_mae: 0.1718 - val_mse: 0.3235 - learning_rate: 0.0010\n",
      "Epoch 16/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - loss: 0.0702 - mae: 0.1719 - mse: 0.3313 - val_loss: 0.0677 - val_mae: 0.1653 - val_mse: 0.3214 - learning_rate: 0.0010\n",
      "Epoch 17/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - loss: 0.0693 - mae: 0.1703 - mse: 0.3244 - val_loss: 0.0668 - val_mae: 0.1651 - val_mse: 0.3155 - learning_rate: 0.0010\n",
      "Epoch 18/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - loss: 0.0664 - mae: 0.1658 - mse: 0.3118 - val_loss: 0.0668 - val_mae: 0.1655 - val_mse: 0.3109 - learning_rate: 0.0010\n",
      "Epoch 19/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - loss: 0.0670 - mae: 0.1667 - mse: 0.3132 - val_loss: 0.0657 - val_mae: 0.1646 - val_mse: 0.3097 - learning_rate: 0.0010\n",
      "Epoch 20/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - loss: 0.0671 - mae: 0.1674 - mse: 0.3141 - val_loss: 0.0653 - val_mae: 0.1659 - val_mse: 0.3044 - learning_rate: 0.0010\n",
      "Epoch 21/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - loss: 0.0652 - mae: 0.1649 - mse: 0.3016 - val_loss: 0.0636 - val_mae: 0.1611 - val_mse: 0.2968 - learning_rate: 0.0010\n",
      "Epoch 22/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - loss: 0.0640 - mae: 0.1629 - mse: 0.2975 - val_loss: 0.0624 - val_mae: 0.1624 - val_mse: 0.2877 - learning_rate: 0.0010\n",
      "Epoch 23/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - loss: 0.0640 - mae: 0.1632 - mse: 0.2969 - val_loss: 0.0616 - val_mae: 0.1590 - val_mse: 0.2829 - learning_rate: 0.0010\n",
      "Epoch 24/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - loss: 0.0632 - mae: 0.1616 - mse: 0.2942 - val_loss: 0.0625 - val_mae: 0.1610 - val_mse: 0.2863 - learning_rate: 0.0010\n",
      "Epoch 25/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - loss: 0.0622 - mae: 0.1608 - mse: 0.2870 - val_loss: 0.0605 - val_mae: 0.1553 - val_mse: 0.2827 - learning_rate: 0.0010\n",
      "Epoch 26/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - loss: 0.0615 - mae: 0.1589 - mse: 0.2860 - val_loss: 0.0604 - val_mae: 0.1555 - val_mse: 0.2812 - learning_rate: 0.0010\n",
      "Epoch 27/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - loss: 0.0600 - mae: 0.1565 - mse: 0.2767 - val_loss: 0.0595 - val_mae: 0.1537 - val_mse: 0.2789 - learning_rate: 0.0010\n",
      "Epoch 28/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - loss: 0.0595 - mae: 0.1557 - mse: 0.2763 - val_loss: 0.0588 - val_mae: 0.1545 - val_mse: 0.2724 - learning_rate: 0.0010\n",
      "Epoch 29/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - loss: 0.0599 - mae: 0.1561 - mse: 0.2758 - val_loss: 0.0593 - val_mae: 0.1541 - val_mse: 0.2731 - learning_rate: 0.0010\n",
      "Epoch 30/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - loss: 0.0583 - mae: 0.1533 - mse: 0.2705 - val_loss: 0.0586 - val_mae: 0.1505 - val_mse: 0.2771 - learning_rate: 0.0010\n",
      "Epoch 31/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - loss: 0.0595 - mae: 0.1548 - mse: 0.2762 - val_loss: 0.0564 - val_mae: 0.1510 - val_mse: 0.2628 - learning_rate: 0.0010\n",
      "Epoch 32/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - loss: 0.0581 - mae: 0.1520 - mse: 0.2706 - val_loss: 0.0576 - val_mae: 0.1511 - val_mse: 0.2720 - learning_rate: 0.0010\n",
      "Epoch 33/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - loss: 0.0576 - mae: 0.1522 - mse: 0.2652 - val_loss: 0.0565 - val_mae: 0.1488 - val_mse: 0.2621 - learning_rate: 0.0010\n",
      "Epoch 34/1000\n",
      "\u001b[1m1773/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0564 - mae: 0.1500 - mse: 0.2619\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - loss: 0.0564 - mae: 0.1500 - mse: 0.2619 - val_loss: 0.0570 - val_mae: 0.1523 - val_mse: 0.2641 - learning_rate: 0.0010\n",
      "Epoch 35/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - loss: 0.0547 - mae: 0.1451 - mse: 0.2556 - val_loss: 0.0515 - val_mae: 0.1386 - val_mse: 0.2408 - learning_rate: 1.0000e-04\n",
      "Epoch 36/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - loss: 0.0507 - mae: 0.1374 - mse: 0.2357 - val_loss: 0.0505 - val_mae: 0.1368 - val_mse: 0.2364 - learning_rate: 1.0000e-04\n",
      "Epoch 37/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - loss: 0.0501 - mae: 0.1369 - mse: 0.2329 - val_loss: 0.0499 - val_mae: 0.1361 - val_mse: 0.2330 - learning_rate: 1.0000e-04\n",
      "Epoch 38/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - loss: 0.0507 - mae: 0.1371 - mse: 0.2386 - val_loss: 0.0495 - val_mae: 0.1355 - val_mse: 0.2312 - learning_rate: 1.0000e-04\n",
      "Epoch 39/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - loss: 0.0489 - mae: 0.1352 - mse: 0.2260 - val_loss: 0.0492 - val_mae: 0.1355 - val_mse: 0.2290 - learning_rate: 1.0000e-04\n",
      "Epoch 40/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - loss: 0.0486 - mae: 0.1351 - mse: 0.2251 - val_loss: 0.0489 - val_mae: 0.1352 - val_mse: 0.2268 - learning_rate: 1.0000e-04\n",
      "Epoch 41/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - loss: 0.0497 - mae: 0.1366 - mse: 0.2305 - val_loss: 0.0485 - val_mae: 0.1344 - val_mse: 0.2255 - learning_rate: 1.0000e-04\n",
      "Epoch 42/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - loss: 0.0485 - mae: 0.1350 - mse: 0.2260 - val_loss: 0.0482 - val_mae: 0.1342 - val_mse: 0.2236 - learning_rate: 1.0000e-04\n",
      "Epoch 43/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - loss: 0.0490 - mae: 0.1353 - mse: 0.2279 - val_loss: 0.0480 - val_mae: 0.1342 - val_mse: 0.2224 - learning_rate: 1.0000e-04\n",
      "Epoch 44/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - loss: 0.0480 - mae: 0.1344 - mse: 0.2221 - val_loss: 0.0479 - val_mae: 0.1339 - val_mse: 0.2210 - learning_rate: 1.0000e-04\n",
      "Epoch 45/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - loss: 0.0492 - mae: 0.1359 - mse: 0.2293 - val_loss: 0.0474 - val_mae: 0.1336 - val_mse: 0.2188 - learning_rate: 1.0000e-04\n",
      "Epoch 46/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - loss: 0.0475 - mae: 0.1342 - mse: 0.2179 - val_loss: 0.0472 - val_mae: 0.1337 - val_mse: 0.2167 - learning_rate: 1.0000e-04\n",
      "Epoch 47/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - loss: 0.0473 - mae: 0.1339 - mse: 0.2184 - val_loss: 0.0470 - val_mae: 0.1334 - val_mse: 0.2154 - learning_rate: 1.0000e-04\n",
      "Epoch 48/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - loss: 0.0477 - mae: 0.1343 - mse: 0.2192 - val_loss: 0.0466 - val_mae: 0.1329 - val_mse: 0.2142 - learning_rate: 1.0000e-04\n",
      "Epoch 49/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - loss: 0.0475 - mae: 0.1346 - mse: 0.2166 - val_loss: 0.0466 - val_mae: 0.1331 - val_mse: 0.2130 - learning_rate: 1.0000e-04\n",
      "Epoch 50/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - loss: 0.0470 - mae: 0.1335 - mse: 0.2157 - val_loss: 0.0462 - val_mae: 0.1326 - val_mse: 0.2116 - learning_rate: 1.0000e-04\n",
      "Epoch 51/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - loss: 0.0459 - mae: 0.1324 - mse: 0.2091 - val_loss: 0.0461 - val_mae: 0.1326 - val_mse: 0.2112 - learning_rate: 1.0000e-04\n",
      "Epoch 52/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - loss: 0.0465 - mae: 0.1336 - mse: 0.2120 - val_loss: 0.0458 - val_mae: 0.1322 - val_mse: 0.2093 - learning_rate: 1.0000e-04\n",
      "Epoch 53/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - loss: 0.0480 - mae: 0.1350 - mse: 0.2223 - val_loss: 0.0458 - val_mae: 0.1319 - val_mse: 0.2095 - learning_rate: 1.0000e-04\n",
      "Epoch 54/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - loss: 0.0461 - mae: 0.1329 - mse: 0.2105 - val_loss: 0.0455 - val_mae: 0.1318 - val_mse: 0.2081 - learning_rate: 1.0000e-04\n",
      "Epoch 55/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - loss: 0.0456 - mae: 0.1319 - mse: 0.2074 - val_loss: 0.0453 - val_mae: 0.1317 - val_mse: 0.2067 - learning_rate: 1.0000e-04\n",
      "Epoch 56/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - loss: 0.0452 - mae: 0.1314 - mse: 0.2059 - val_loss: 0.0453 - val_mae: 0.1316 - val_mse: 0.2064 - learning_rate: 1.0000e-04\n",
      "Epoch 57/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - loss: 0.0474 - mae: 0.1340 - mse: 0.2191 - val_loss: 0.0450 - val_mae: 0.1315 - val_mse: 0.2045 - learning_rate: 1.0000e-04\n",
      "Epoch 58/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - loss: 0.0459 - mae: 0.1325 - mse: 0.2095 - val_loss: 0.0448 - val_mae: 0.1308 - val_mse: 0.2046 - learning_rate: 1.0000e-04\n",
      "Epoch 59/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - loss: 0.0446 - mae: 0.1308 - mse: 0.2045 - val_loss: 0.0447 - val_mae: 0.1314 - val_mse: 0.2028 - learning_rate: 1.0000e-04\n",
      "Epoch 60/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - loss: 0.0458 - mae: 0.1322 - mse: 0.2099 - val_loss: 0.0446 - val_mae: 0.1314 - val_mse: 0.2012 - learning_rate: 1.0000e-04\n",
      "Epoch 61/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - loss: 0.0456 - mae: 0.1325 - mse: 0.2086 - val_loss: 0.0445 - val_mae: 0.1306 - val_mse: 0.2021 - learning_rate: 1.0000e-04\n",
      "Epoch 62/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - loss: 0.0442 - mae: 0.1310 - mse: 0.1991 - val_loss: 0.0442 - val_mae: 0.1306 - val_mse: 0.2000 - learning_rate: 1.0000e-04\n",
      "Epoch 63/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - loss: 0.0450 - mae: 0.1312 - mse: 0.2060 - val_loss: 0.0439 - val_mae: 0.1302 - val_mse: 0.1994 - learning_rate: 1.0000e-04\n",
      "Epoch 64/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - loss: 0.0439 - mae: 0.1305 - mse: 0.1984 - val_loss: 0.0437 - val_mae: 0.1303 - val_mse: 0.1977 - learning_rate: 1.0000e-04\n",
      "Epoch 65/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - loss: 0.0446 - mae: 0.1316 - mse: 0.2016 - val_loss: 0.0437 - val_mae: 0.1300 - val_mse: 0.1977 - learning_rate: 1.0000e-04\n",
      "Epoch 66/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - loss: 0.0450 - mae: 0.1319 - mse: 0.2032 - val_loss: 0.0434 - val_mae: 0.1289 - val_mse: 0.1977 - learning_rate: 1.0000e-04\n",
      "Epoch 67/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - loss: 0.0433 - mae: 0.1295 - mse: 0.1951 - val_loss: 0.0434 - val_mae: 0.1294 - val_mse: 0.1971 - learning_rate: 1.0000e-04\n",
      "Epoch 68/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - loss: 0.0426 - mae: 0.1280 - mse: 0.1939 - val_loss: 0.0431 - val_mae: 0.1288 - val_mse: 0.1954 - learning_rate: 1.0000e-04\n",
      "Epoch 69/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - loss: 0.0423 - mae: 0.1281 - mse: 0.1907 - val_loss: 0.0429 - val_mae: 0.1288 - val_mse: 0.1942 - learning_rate: 1.0000e-04\n",
      "Epoch 70/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - loss: 0.0431 - mae: 0.1294 - mse: 0.1938 - val_loss: 0.0428 - val_mae: 0.1286 - val_mse: 0.1937 - learning_rate: 1.0000e-04\n",
      "Epoch 71/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - loss: 0.0441 - mae: 0.1307 - mse: 0.1994 - val_loss: 0.0427 - val_mae: 0.1285 - val_mse: 0.1929 - learning_rate: 1.0000e-04\n",
      "Epoch 72/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - loss: 0.0429 - mae: 0.1288 - mse: 0.1932 - val_loss: 0.0425 - val_mae: 0.1281 - val_mse: 0.1929 - learning_rate: 1.0000e-04\n",
      "Epoch 73/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 7ms/step - loss: 0.0424 - mae: 0.1282 - mse: 0.1916 - val_loss: 0.0424 - val_mae: 0.1281 - val_mse: 0.1919 - learning_rate: 1.0000e-04\n",
      "Epoch 74/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - loss: 0.0429 - mae: 0.1287 - mse: 0.1925 - val_loss: 0.0426 - val_mae: 0.1279 - val_mse: 0.1929 - learning_rate: 1.0000e-04\n",
      "Epoch 75/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - loss: 0.0432 - mae: 0.1297 - mse: 0.1944 - val_loss: 0.0422 - val_mae: 0.1276 - val_mse: 0.1907 - learning_rate: 1.0000e-04\n",
      "Epoch 76/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - loss: 0.0412 - mae: 0.1267 - mse: 0.1856 - val_loss: 0.0420 - val_mae: 0.1276 - val_mse: 0.1896 - learning_rate: 1.0000e-04\n",
      "Epoch 77/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - loss: 0.0432 - mae: 0.1291 - mse: 0.1965 - val_loss: 0.0420 - val_mae: 0.1272 - val_mse: 0.1899 - learning_rate: 1.0000e-04\n",
      "Epoch 78/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - loss: 0.0426 - mae: 0.1282 - mse: 0.1943 - val_loss: 0.0419 - val_mae: 0.1275 - val_mse: 0.1894 - learning_rate: 1.0000e-04\n",
      "Epoch 79/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - loss: 0.0407 - mae: 0.1260 - mse: 0.1825 - val_loss: 0.0417 - val_mae: 0.1269 - val_mse: 0.1884 - learning_rate: 1.0000e-04\n",
      "Epoch 80/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - loss: 0.0417 - mae: 0.1269 - mse: 0.1889 - val_loss: 0.0417 - val_mae: 0.1270 - val_mse: 0.1880 - learning_rate: 1.0000e-04\n",
      "Epoch 81/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - loss: 0.0421 - mae: 0.1279 - mse: 0.1899 - val_loss: 0.0418 - val_mae: 0.1270 - val_mse: 0.1893 - learning_rate: 1.0000e-04\n",
      "Epoch 82/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - loss: 0.0417 - mae: 0.1274 - mse: 0.1864 - val_loss: 0.0415 - val_mae: 0.1272 - val_mse: 0.1860 - learning_rate: 1.0000e-04\n",
      "Epoch 83/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - loss: 0.0400 - mae: 0.1252 - mse: 0.1777 - val_loss: 0.0413 - val_mae: 0.1260 - val_mse: 0.1871 - learning_rate: 1.0000e-04\n",
      "Epoch 84/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - loss: 0.0413 - mae: 0.1270 - mse: 0.1859 - val_loss: 0.0411 - val_mae: 0.1263 - val_mse: 0.1851 - learning_rate: 1.0000e-04\n",
      "Epoch 85/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - loss: 0.0415 - mae: 0.1267 - mse: 0.1872 - val_loss: 0.0410 - val_mae: 0.1260 - val_mse: 0.1851 - learning_rate: 1.0000e-04\n",
      "Epoch 86/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - loss: 0.0401 - mae: 0.1246 - mse: 0.1795 - val_loss: 0.0409 - val_mae: 0.1258 - val_mse: 0.1847 - learning_rate: 1.0000e-04\n",
      "Epoch 87/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - loss: 0.0413 - mae: 0.1262 - mse: 0.1859 - val_loss: 0.0409 - val_mae: 0.1258 - val_mse: 0.1842 - learning_rate: 1.0000e-04\n",
      "Epoch 88/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - loss: 0.0407 - mae: 0.1258 - mse: 0.1814 - val_loss: 0.0408 - val_mae: 0.1254 - val_mse: 0.1843 - learning_rate: 1.0000e-04\n",
      "Epoch 89/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - loss: 0.0405 - mae: 0.1253 - mse: 0.1807 - val_loss: 0.0408 - val_mae: 0.1259 - val_mse: 0.1830 - learning_rate: 1.0000e-04\n",
      "Epoch 90/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - loss: 0.0424 - mae: 0.1278 - mse: 0.1926 - val_loss: 0.0409 - val_mae: 0.1254 - val_mse: 0.1844 - learning_rate: 1.0000e-04\n",
      "Epoch 91/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - loss: 0.0410 - mae: 0.1259 - mse: 0.1846 - val_loss: 0.0404 - val_mae: 0.1250 - val_mse: 0.1822 - learning_rate: 1.0000e-04\n",
      "Epoch 92/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - loss: 0.0405 - mae: 0.1248 - mse: 0.1828 - val_loss: 0.0403 - val_mae: 0.1246 - val_mse: 0.1819 - learning_rate: 1.0000e-04\n",
      "Epoch 93/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - loss: 0.0397 - mae: 0.1236 - mse: 0.1800 - val_loss: 0.0405 - val_mae: 0.1250 - val_mse: 0.1822 - learning_rate: 1.0000e-04\n",
      "Epoch 94/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - loss: 0.0416 - mae: 0.1266 - mse: 0.1895 - val_loss: 0.0402 - val_mae: 0.1246 - val_mse: 0.1809 - learning_rate: 1.0000e-04\n",
      "Epoch 95/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - loss: 0.0400 - mae: 0.1244 - mse: 0.1792 - val_loss: 0.0400 - val_mae: 0.1240 - val_mse: 0.1811 - learning_rate: 1.0000e-04\n",
      "Epoch 96/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - loss: 0.0403 - mae: 0.1250 - mse: 0.1811 - val_loss: 0.0401 - val_mae: 0.1240 - val_mse: 0.1813 - learning_rate: 1.0000e-04\n",
      "Epoch 97/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - loss: 0.0399 - mae: 0.1239 - mse: 0.1804 - val_loss: 0.0399 - val_mae: 0.1238 - val_mse: 0.1801 - learning_rate: 1.0000e-04\n",
      "Epoch 98/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - loss: 0.0419 - mae: 0.1267 - mse: 0.1902 - val_loss: 0.0400 - val_mae: 0.1241 - val_mse: 0.1803 - learning_rate: 1.0000e-04\n",
      "Epoch 99/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - loss: 0.0411 - mae: 0.1258 - mse: 0.1858 - val_loss: 0.0397 - val_mae: 0.1237 - val_mse: 0.1793 - learning_rate: 1.0000e-04\n",
      "Epoch 100/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - loss: 0.0407 - mae: 0.1248 - mse: 0.1846 - val_loss: 0.0397 - val_mae: 0.1233 - val_mse: 0.1796 - learning_rate: 1.0000e-04\n",
      "Epoch 101/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - loss: 0.0413 - mae: 0.1259 - mse: 0.1862 - val_loss: 0.0397 - val_mae: 0.1236 - val_mse: 0.1789 - learning_rate: 1.0000e-04\n",
      "Epoch 102/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - loss: 0.0397 - mae: 0.1240 - mse: 0.1792 - val_loss: 0.0396 - val_mae: 0.1236 - val_mse: 0.1787 - learning_rate: 1.0000e-04\n",
      "Epoch 103/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - loss: 0.0383 - mae: 0.1216 - mse: 0.1711 - val_loss: 0.0396 - val_mae: 0.1235 - val_mse: 0.1790 - learning_rate: 1.0000e-04\n",
      "Epoch 104/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - loss: 0.0407 - mae: 0.1250 - mse: 0.1850 - val_loss: 0.0396 - val_mae: 0.1229 - val_mse: 0.1789 - learning_rate: 1.0000e-04\n",
      "Epoch 105/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - loss: 0.0393 - mae: 0.1228 - mse: 0.1774 - val_loss: 0.0392 - val_mae: 0.1224 - val_mse: 0.1773 - learning_rate: 1.0000e-04\n",
      "Epoch 106/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - loss: 0.0389 - mae: 0.1227 - mse: 0.1739 - val_loss: 0.0393 - val_mae: 0.1228 - val_mse: 0.1771 - learning_rate: 1.0000e-04\n",
      "Epoch 107/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - loss: 0.0389 - mae: 0.1227 - mse: 0.1743 - val_loss: 0.0393 - val_mae: 0.1233 - val_mse: 0.1765 - learning_rate: 1.0000e-04\n",
      "Epoch 108/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - loss: 0.0390 - mae: 0.1226 - mse: 0.1742 - val_loss: 0.0391 - val_mae: 0.1224 - val_mse: 0.1765 - learning_rate: 1.0000e-04\n",
      "Epoch 109/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - loss: 0.0380 - mae: 0.1211 - mse: 0.1695 - val_loss: 0.0390 - val_mae: 0.1222 - val_mse: 0.1760 - learning_rate: 1.0000e-04\n",
      "Epoch 110/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - loss: 0.0396 - mae: 0.1229 - mse: 0.1798 - val_loss: 0.0390 - val_mae: 0.1224 - val_mse: 0.1761 - learning_rate: 1.0000e-04\n",
      "Epoch 111/1000\n",
      "\u001b[1m1772/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0386 - mae: 0.1221 - mse: 0.1725\n",
      "Epoch 111: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - loss: 0.0386 - mae: 0.1221 - mse: 0.1725 - val_loss: 0.0391 - val_mae: 0.1222 - val_mse: 0.1762 - learning_rate: 1.0000e-04\n",
      "Epoch 112/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - loss: 0.0389 - mae: 0.1217 - mse: 0.1765 - val_loss: 0.0385 - val_mae: 0.1211 - val_mse: 0.1741 - learning_rate: 1.0000e-05\n",
      "Epoch 113/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - loss: 0.0382 - mae: 0.1209 - mse: 0.1714 - val_loss: 0.0384 - val_mae: 0.1209 - val_mse: 0.1738 - learning_rate: 1.0000e-05\n",
      "Epoch 114/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - loss: 0.0386 - mae: 0.1211 - mse: 0.1752 - val_loss: 0.0383 - val_mae: 0.1208 - val_mse: 0.1736 - learning_rate: 1.0000e-05\n",
      "Epoch 115/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - loss: 0.0387 - mae: 0.1209 - mse: 0.1763 - val_loss: 0.0383 - val_mae: 0.1207 - val_mse: 0.1735 - learning_rate: 1.0000e-05\n",
      "Epoch 116/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - loss: 0.0384 - mae: 0.1209 - mse: 0.1750 - val_loss: 0.0383 - val_mae: 0.1208 - val_mse: 0.1732 - learning_rate: 1.0000e-05\n",
      "Epoch 117/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0387 - mae: 0.1214 - mse: 0.1765\n",
      "Epoch 117: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - loss: 0.0387 - mae: 0.1214 - mse: 0.1765 - val_loss: 0.0382 - val_mae: 0.1207 - val_mse: 0.1732 - learning_rate: 1.0000e-05\n",
      "Epoch 118/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - loss: 0.0379 - mae: 0.1207 - mse: 0.1705 - val_loss: 0.0382 - val_mae: 0.1207 - val_mse: 0.1732 - learning_rate: 1.0000e-06\n",
      "Epoch 119/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - loss: 0.0381 - mae: 0.1206 - mse: 0.1718 - val_loss: 0.0382 - val_mae: 0.1207 - val_mse: 0.1732 - learning_rate: 1.0000e-06\n",
      "Epoch 120/1000\n",
      "\u001b[1m1773/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0386 - mae: 0.1214 - mse: 0.1739\n",
      "Epoch 120: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - loss: 0.0386 - mae: 0.1214 - mse: 0.1739 - val_loss: 0.0382 - val_mae: 0.1207 - val_mse: 0.1732 - learning_rate: 1.0000e-06\n",
      "Epoch 121/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - loss: 0.0385 - mae: 0.1217 - mse: 0.1736 - val_loss: 0.0382 - val_mae: 0.1207 - val_mse: 0.1732 - learning_rate: 1.0000e-07\n",
      "Epoch 122/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - loss: 0.0383 - mae: 0.1208 - mse: 0.1721 - val_loss: 0.0382 - val_mae: 0.1207 - val_mse: 0.1732 - learning_rate: 1.0000e-07\n",
      "Epoch 123/1000\n",
      "\u001b[1m1770/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0394 - mae: 0.1220 - mse: 0.1788\n",
      "Epoch 123: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - loss: 0.0394 - mae: 0.1220 - mse: 0.1788 - val_loss: 0.0382 - val_mae: 0.1207 - val_mse: 0.1732 - learning_rate: 1.0000e-07\n",
      "Epoch 124/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - loss: 0.0387 - mae: 0.1214 - mse: 0.1765 - val_loss: 0.0382 - val_mae: 0.1207 - val_mse: 0.1732 - learning_rate: 1.0000e-08\n",
      "Epoch 125/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - loss: 0.0373 - mae: 0.1200 - mse: 0.1649 - val_loss: 0.0382 - val_mae: 0.1207 - val_mse: 0.1732 - learning_rate: 1.0000e-08\n",
      "Epoch 126/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0382 - mae: 0.1207 - mse: 0.1724\n",
      "Epoch 126: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-09.\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - loss: 0.0382 - mae: 0.1207 - mse: 0.1724 - val_loss: 0.0382 - val_mae: 0.1207 - val_mse: 0.1732 - learning_rate: 1.0000e-08\n",
      "Epoch 127/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - loss: 0.0379 - mae: 0.1204 - mse: 0.1705 - val_loss: 0.0382 - val_mae: 0.1207 - val_mse: 0.1732 - learning_rate: 1.0000e-09\n",
      "Epoch 128/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - loss: 0.0380 - mae: 0.1201 - mse: 0.1730 - val_loss: 0.0382 - val_mae: 0.1207 - val_mse: 0.1732 - learning_rate: 1.0000e-09\n",
      "Epoch 129/1000\n",
      "\u001b[1m1768/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0389 - mae: 0.1217 - mse: 0.1769\n",
      "Epoch 129: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-10.\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - loss: 0.0389 - mae: 0.1217 - mse: 0.1769 - val_loss: 0.0382 - val_mae: 0.1207 - val_mse: 0.1732 - learning_rate: 1.0000e-09\n",
      "Epoch 130/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - loss: 0.0393 - mae: 0.1219 - mse: 0.1805 - val_loss: 0.0382 - val_mae: 0.1207 - val_mse: 0.1732 - learning_rate: 1.0000e-10\n",
      "Epoch 131/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - loss: 0.0379 - mae: 0.1202 - mse: 0.1705 - val_loss: 0.0382 - val_mae: 0.1207 - val_mse: 0.1732 - learning_rate: 1.0000e-10\n",
      "Epoch 132/1000\n",
      "\u001b[1m1772/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0384 - mae: 0.1209 - mse: 0.1750\n",
      "Epoch 132: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-11.\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - loss: 0.0384 - mae: 0.1209 - mse: 0.1750 - val_loss: 0.0382 - val_mae: 0.1207 - val_mse: 0.1732 - learning_rate: 1.0000e-10\n",
      "Epoch 133/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - loss: 0.0392 - mae: 0.1215 - mse: 0.1782 - val_loss: 0.0382 - val_mae: 0.1207 - val_mse: 0.1732 - learning_rate: 1.0000e-11\n",
      "Epoch 134/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - loss: 0.0384 - mae: 0.1204 - mse: 0.1737 - val_loss: 0.0382 - val_mae: 0.1207 - val_mse: 0.1732 - learning_rate: 1.0000e-11\n",
      "Epoch 135/1000\n",
      "\u001b[1m1772/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0396 - mae: 0.1223 - mse: 0.1791\n",
      "Epoch 135: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-12.\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - loss: 0.0396 - mae: 0.1223 - mse: 0.1790 - val_loss: 0.0382 - val_mae: 0.1207 - val_mse: 0.1732 - learning_rate: 1.0000e-11\n",
      "Epoch 136/1000\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - loss: 0.0382 - mae: 0.1207 - mse: 0.1730 - val_loss: 0.0382 - val_mae: 0.1207 - val_mse: 0.1732 - learning_rate: 1.0000e-12\n",
      "Epoch 136: early stopping\n"
     ]
    }
   ],
   "source": [
    "huber_loss = Huber(delta=1.0)\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(6, 7), return_sequences=True))\n",
    "model.add(LSTM(64, return_sequences=True))\n",
    "model.add(LSTM(32, return_sequences=True))\n",
    "model.add(TimeDistributed(Dense(7, activation='linear')))\n",
    "model.summary()\n",
    "model.compile(optimizer='adam', loss=huber_loss, metrics=['mse','mae'])\n",
    "checkpoint = ModelCheckpoint(model_name + '_best.keras', monitor='val_loss', save_best_only=True)\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, verbose=1)\n",
    "hist = model.fit(japonica_training_features_X_chunks_crop, japonica_training_features_y_chunks_crop, epochs = 1000, batch_size = 6, validation_data=(japonica_validation_features_X_chunks_crop, japonica_validation_features_y_chunks_crop), callbacks=[checkpoint, early_stop, reduce_lr])\n",
    "model.save(model_name+'.keras')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "doRegressor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
